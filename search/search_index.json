{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HTTPX A next-generation HTTP client for Python. HTTPX is a fully featured HTTP client for Python 3, which provides sync and async APIs, and support for both HTTP/1.1 and HTTP/2. Note HTTPX should currently be considered in beta. We believe we've got the public API to a stable point now, but would strongly recommend pinning your dependencies to the 0.11.* release, so that you're able to properly review API changes between package updates . A 1.0 release is expected to be issued sometime on or before April 2020. Let's get started... >>> import httpx >>> r = httpx . get ( 'https://www.example.org/' ) >>> r < Response [ 200 OK ] > >>> r . status_code 200 >>> r . headers [ 'content-type' ] 'text/html; charset=UTF-8' >>> r . text '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' Or, using the async API... Use IPython or Python 3.8+ with python -m asyncio to try this code interactively. >>> import httpx >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.org/' ) >>> r < Response [ 200 OK ] > Features HTTPX is a high performance asynchronous HTTP client, that builds on the well-established usability of requests , and gives you: A broadly requests-compatible API . Standard synchronous interface, but with async support if you need it . HTTP/1.1 and HTTP/2 support . Ability to make requests directly to WSGI applications or ASGI applications . Strict timeouts everywhere. Fully type annotated. 99% test coverage. Plus all the standard features of requests ... International Domains and URLs Keep-Alive & Connection Pooling Sessions with Cookie Persistence Browser-style SSL Verification Basic/Digest Authentication Elegant Key/Value Cookies Automatic Decompression Automatic Content Decoding Unicode Response Bodies Multipart File Uploads HTTP(S) Proxy Support Connection Timeouts Streaming Downloads .netrc Support Chunked Requests Documentation For a run-through of all the basics, head over to the QuickStart . For more advanced topics, see the Advanced Usage section, the async support section, or the HTTP/2 section. The Developer Interface provides a comprehensive API reference. Dependencies The HTTPX project relies on these excellent libraries: urllib3 - Sync client support. h11 - HTTP/1.1 support. h2 - HTTP/2 support. certifi - SSL certificates. chardet - Fallback auto-detection for response encoding. hstspreload - determines whether IDNA-encoded host should be only accessed via HTTPS. idna - Internationalized domain name support. rfc3986 - URL parsing & normalization. brotlipy - Decoding for \"brotli\" compressed responses. (Optional) A huge amount of credit is due to requests for the API layout that much of this work follows, as well as to urllib3 for plenty of design inspiration around the lower-level networking details. Installation Install with pip: $ pip install httpx HTTPX requires Python 3.6+","title":"Introduction"},{"location":"#features","text":"HTTPX is a high performance asynchronous HTTP client, that builds on the well-established usability of requests , and gives you: A broadly requests-compatible API . Standard synchronous interface, but with async support if you need it . HTTP/1.1 and HTTP/2 support . Ability to make requests directly to WSGI applications or ASGI applications . Strict timeouts everywhere. Fully type annotated. 99% test coverage. Plus all the standard features of requests ... International Domains and URLs Keep-Alive & Connection Pooling Sessions with Cookie Persistence Browser-style SSL Verification Basic/Digest Authentication Elegant Key/Value Cookies Automatic Decompression Automatic Content Decoding Unicode Response Bodies Multipart File Uploads HTTP(S) Proxy Support Connection Timeouts Streaming Downloads .netrc Support Chunked Requests","title":"Features"},{"location":"#documentation","text":"For a run-through of all the basics, head over to the QuickStart . For more advanced topics, see the Advanced Usage section, the async support section, or the HTTP/2 section. The Developer Interface provides a comprehensive API reference.","title":"Documentation"},{"location":"#dependencies","text":"The HTTPX project relies on these excellent libraries: urllib3 - Sync client support. h11 - HTTP/1.1 support. h2 - HTTP/2 support. certifi - SSL certificates. chardet - Fallback auto-detection for response encoding. hstspreload - determines whether IDNA-encoded host should be only accessed via HTTPS. idna - Internationalized domain name support. rfc3986 - URL parsing & normalization. brotlipy - Decoding for \"brotli\" compressed responses. (Optional) A huge amount of credit is due to requests for the API layout that much of this work follows, as well as to urllib3 for plenty of design inspiration around the lower-level networking details.","title":"Dependencies"},{"location":"#installation","text":"Install with pip: $ pip install httpx HTTPX requires Python 3.6+","title":"Installation"},{"location":"advanced/","text":"Advanced Usage Client Instances Using a Client instance to make requests will give you HTTP connection pooling, will provide cookie persistence, and allows you to apply configuration across all outgoing requests. Hint A Client instance is equivalent to a Session instance in requests . Note Starting from httpx==0.10.0 , the default and recommended Client class is AsyncClient . This should help prevent breaking changes once sync support is reintroduced. A Client synonym remains for compatibility with httpx==0.9.* releases, but you are encouraged to migrate to AsyncClient as soon as possible. Usage The recommended way to use a Client is as a context manager. This will ensure that connections are properly cleaned up when leaving the with block: >>> with httpx . Client () as client : ... r = client . get ( 'https://example.com' ) ... >>> r < Response [ 200 OK ] > Alternatively, you can explicitly close the connection pool without block-usage using .close() : >>> client = httpx . Client () >>> try : ... r = client . get ( 'https://example.com' ) ... finally : ... client . close () ... >>> r < Response [ 200 OK ] > Once you have a Client , you can use all the features documented in the Quickstart guide. Configuration Clients allow you to apply configuration to all outgoing requests by passing parameters to the Client constructor. For example, to apply a set of custom headers on every request: >>> url = 'http://httpbin.org/headers' >>> headers = { 'user-agent' : 'my-app/0.0.1' } >>> with httpx . Client ( headers = headers ) as client : ... r = client . get ( url ) ... >>> r . json ()[ 'headers' ][ 'User-Agent' ] 'my-app/0.0.1' Note When you provide a parameter at both the client and request levels, one of two things can happen: For headers, query parameters and cookies, the values are merged into one. For all other parameters, the request-level value is used. Additionally, Client accepts some parameters that aren't available at the request level. One particularly useful parameter is base_url , which allows you to define a base URL to prepend to all outgoing requests: >>> with httpx . Client ( base_url = 'http://httpbin.org' ) as client : ... r = client . get ( '/headers' ) ... >>> r . request . url URL ( 'http://httpbin.org/headers' ) For a list of all available client-level parameters, see the Client API reference . Calling into Python Web Apps You can configure an httpx client to call directly into a Python web application using the WSGI protocol. This is particularly useful for two main use-cases: Using httpx as a client inside test cases. Mocking out external services during tests or in dev/staging environments. Here's an example of integrating against a Flask application: from flask import Flask import httpx app = Flask ( __name__ ) @app . route ( \"/\" ) def hello (): return \"Hello World!\" with httpx . Client ( app = app , base_url = \"http://testserver\" ) as client : r = client . get ( \"/\" ) assert r . status_code == 200 assert r . text == \"Hello World!\" For some more complex cases you might need to customize the WSGI dispatch. This allows you to: Inspect 500 error responses rather than raise exceptions by setting raise_app_exceptions=False . Mount the WSGI application at a subpath by setting script_name (WSGI). Use a given client address for requests by setting remote_addr (WSGI). For example: # Instantiate a client that makes WSGI requests with a client IP of \"1.2.3.4\". dispatch = httpx . WSGIDispatch ( app = app , remote_addr = \"1.2.3.4\" ) with httpx . Client ( dispatch = dispatch , base_url = \"http://testserver\" ) as client : ... Build Request You can use Client.build_request() to build a request and make modifications before sending the request. >>> with httpx . Client () as client : ... req = client . build_request ( \"OPTIONS\" , \"https://example.com\" ) ... req . url . full_path = \"*\" # Build an 'OPTIONS *' request for CORS ... r = client . send ( req ) ... >>> r < Response [ 200 OK ] > .netrc Support HTTPX supports .netrc file. In trust_env=True cases, if auth parameter is not defined, HTTPX tries to add auth into request's header from .netrc file. Note The NETRC file is cached across requests made by a client. If you need to refresh the cache (e.g. because the NETRC file has changed), you should create a new client or restart the interpreter. As default trust_env is true. To set false: >>> httpx . get ( 'https://example.org/' , trust_env = False ) If NETRC environment is empty, HTTPX tries to use default files. ( ~/.netrc , ~/_netrc ) To change NETRC environment: >>> import os >>> os . environ [ \"NETRC\" ] = \"my_default_folder/.my_netrc\" .netrc file content example: machine netrcexample . org login example - username password example - password ... When using Client instances, trust_env should be set on the client itself, rather that on the request methods: client = httpx . Client ( trust_env = False ) HTTP Proxying HTTPX supports setting up HTTP proxies the same way that Requests does via the proxies parameter. For example to forward all HTTP traffic to http://127.0.0.1:3080 and all HTTPS traffic to http://127.0.0.1:3081 your proxies config would look like this: >>> proxies = { ... \"http\" : \"http://127.0.0.1:3080\" , ... \"https\" : \"http://127.0.0.1:3081\" ... } >>> with httpx . Client ( proxies = proxies ) as client : ... ... Credentials may be passed in as part of the URL in the standard way, i.e. http://username:password@127.0.0.1:3080 . Proxies can be configured for a specific scheme and host, all schemes of a host, all hosts for a scheme, or for all requests. When determining which proxy configuration to use for a given request this same order is used. >>> proxies = { ... \"http://example.com\" : \"...\" , # Host+Scheme ... \"all://example.com\" : \"...\" , # Host ... \"http\" : \"...\" , # Scheme ... \"all\" : \"...\" , # All ... } >>> with httpx . Client ( proxies = proxies ) as client : ... ... ... >>> proxy = \"...\" # Shortcut for {'all': '...'} >>> with httpx . Client ( proxies = proxy ) as client : ... ... Warning To make sure that proxies cannot read your traffic, and even if the proxy_url uses HTTPS, it is recommended to use HTTPS and tunnel requests if possible. By default httpx.Proxy will operate as a forwarding proxy for http://... requests and will establish a CONNECT TCP tunnel for https:// requests. This doesn't change regardless of the proxy url being http or https . Proxies can be configured to have different behavior such as forwarding or tunneling all requests: proxy = httpx . Proxy ( url = \"https://127.0.0.1\" , mode = \"TUNNEL_ONLY\" # May be \"TUNNEL_ONLY\" or \"FORWARD_ONLY\". Defaults to \"DEFAULT\". ) with httpx . Client ( proxies = proxy ) as client : # This request will be tunneled instead of forwarded. r = client . get ( \"http://example.com\" ) Note To use proxies you must pass the proxy information at Client initialization, rather than on the .get(...) call or other request methods. SOCKS proxies are not supported yet. Timeout Configuration HTTPX is careful to enforce timeouts everywhere by default. The default behavior is to raise a TimeoutException after 5 seconds of network inactivity. Setting and disabling timeouts You can set timeouts for an individual request: # Using the top-level API: httpx . get ( 'http://example.com/api/v1/example' , timeout = 10.0 ) # Using a client instance: with httpx . Client () as client : client . get ( \"http://example.com/api/v1/example\" , timeout = 10.0 ) Or disable timeouts for an individual request: # Using the top-level API: httpx . get ( 'http://example.com/api/v1/example' , timeout = None ) # Using a client instance: with httpx . Client () as client : client . get ( \"http://example.com/api/v1/example\" , timeout = None ) Setting a default timeout on a client You can set a timeout on a client instance, which results in the given timeout being used as the default for requests made with this client: client = httpx . Client () # Use a default 5s timeout everywhere. client = httpx . Client ( timeout = 10.0 ) # Use a default 10s timeout everywhere. client = httpx . Client ( timeout = None ) # Disable all timeouts by default. Fine tuning the configuration HTTPX also allows you to specify the timeout behavior in more fine grained detail. There are four different types of timeouts that may occur. These are connect , read , write , and pool timeouts. The connect timeout specifies the maximum amount of time to wait until a connection to the requested host is established. If HTTPX is unable to connect within this time frame, a ConnectTimeout exception is raised. The read timeout specifies the maximum duration to wait for a chunk of data to be received (for example, a chunk of the response body). If HTTPX is unable to receive data within this time frame, a ReadTimeout exception is raised. The write timeout specifies the maximum duration to wait for a chunk of data to be sent (for example, a chunk of the request body). If HTTPX is unable to send data within this time frame, a WriteTimeout exception is raised. The pool timeout specifies the maximum duration to wait for acquiring a connection from the connection pool. If HTTPX is unable to acquire a connection within this time frame, a PoolTimeout exception is raised. A related configuration here is the maximum number of allowable connections in the connection pool, which is configured by the pool_limits . You can configure the timeout behavior for any of these values... # A client with a 60s timeout for connecting, and a 10s timeout elsewhere. timeout = httpx . Timeout ( 10.0 , connect_timeout = 60.0 ) client = httpx . Client ( timeout = timeout ) response = client . get ( 'http://example.com/' ) Multipart file encoding As mentioned in the quickstart multipart file encoding is available by passing a dictionary with the name of the payloads as keys and either tuple of elements or a file-like object or a string as values. >>> files = { 'upload-file' : ( 'report.xls' , open ( 'report.xls' , 'rb' ), 'application/vnd.ms-excel' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } More specifically, if a tuple is used as a value, it must have between 2 and 3 elements: The first element is an optional file name which can be set to None . The second element may be a file-like object or a string which will be automatically encoded in UTF-8. An optional third element can be used to specify the MIME type of the file being uploaded. If not specified HTTPX will attempt to guess the MIME type based on the file name, with unknown file extensions defaulting to \"application/octet-stream\". If the file name is explicitly set to None then HTTPX will not include a content-type MIME header field. >>> files = { 'upload-file' : ( None , 'text content' , 'text/plain' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : {}, \"form\" : { \"upload-file\" : \"text-content\" }, ... } Customizing authentication When issuing requests or instantiating a client, the auth argument can be used to pass an authentication scheme to use. The auth argument may be one of the following... A two-tuple of username / password , to be used with basic authentication. An instance of httpx.BasicAuth() or httpx.DigestAuth() . A callable, accepting a request and returning an authenticated request instance. A subclass of httpx.Auth . The most involved of these is the last, which allows you to create authentication flows involving one or more requests. A subclass of httpx.Auth should implement def auth_flow(request) , and yield any requests that need to be made... class MyCustomAuth ( httpx . Auth ): def __init__ ( self , token ): self . token = token def auth_flow ( self , request ): # Send the request, with a custom `X-Authentication` header. request . headers [ 'X-Authentication' ] = self . token yield request If the auth flow requires more that one request, you can issue multiple yields, and obtain the response in each case... class MyCustomAuth ( httpx . Auth ): def __init__ ( self , token ): self . token = token def auth_flow ( self , request ): response = yield request if response . status_code == 401 : # If the server issues a 401 response then resend the request, # with a custom `X-Authentication` header. request . headers [ 'X-Authentication' ] = self . token yield request Custom authentication classes are designed to not perform any I/O, so that they may be used with both sync and async client instances. If you are implementing an authentication scheme that requires the request body, then you need to indicate this on the class using a requires_request_body property. You will then be able to access request.content inside the .auth_flow() method. class MyCustomAuth ( httpx . Auth ): requires_request_body = True def __init__ ( self , token ): self . token = token def auth_flow ( self , request ): response = yield request if response . status_code == 401 : # If the server issues a 401 response then resend the request, # with a custom `X-Authentication` header. request . headers [ 'X-Authentication' ] = self . sign_request ( ... ) yield request def sign_request ( self , request ): # Create a request signature, based on `request.method`, `request.url`, # `request.headers`, and `request.content`. ... Similarly, if you are implementing a scheme that requires access to the response body, then use the requires_response_body property. You will then be able to access response body properties and methods such as response.content , response.text , response.json() , etc. class MyCustomAuth ( httpx . Auth ): requires_response_body = True def __init__ ( self , access_token , refresh_token , refresh_url ): self . access_token = access_token self . refresh_token = refresh_token self . refresh_url = refresh_url def auth_flow ( self , request ): request . headers [ \"X-Authentication\" ] = self . access_token response = yield request if response . status_code == 401 : # If the server issues a 401 response, then issue a request to # refresh tokens, and resend the request. refresh_response = yield self . build_refresh_request () self . update_tokens ( refresh_response ) request . headers [ \"X-Authentication\" ] = self . access_token yield request def build_refresh_request ( self ): # Return an `httpx.Request` for refreshing tokens. ... def update_tokens ( self , response ): # Update the `.access_token` and `.refresh_token` tokens # based on a refresh response. data = response . json () ... SSL certificates When making a request over HTTPS, HTTPX needs to verify the identity of the requested host. To do this, it uses a bundle of SSL certificates (a.k.a. CA bundle) delivered by a trusted certificate authority (CA). Changing the verification defaults By default, HTTPX uses the CA bundle provided by Certifi . This is what you want in most cases, even though some advanced situations may require you to use a different set of certificates. If you'd like to use a custom CA bundle, you can use the verify parameter. import httpx r = httpx . get ( \"https://example.org\" , verify = \"path/to/client.pem\" ) You can also disable the SSL verification... import httpx r = httpx . get ( \"https://example.org\" , verify = False ) SSL configuration on client instances If you're using a Client() instance, then you should pass any SSL settings when instantiating the client. client = httpx . Client ( verify = False ) The client.get(...) method and other request methods do not support changing the SSL settings on a per-request basis. If you need different SSL settings in different cases you should use more that one client instance, with different settings on each. Each client will then be using an isolated connection pool with a specific fixed SSL configuration on all connections within that pool. Making HTTPS requests to a local server When making requests to local servers, such as a development server running on localhost , you will typically be using unencrypted HTTP connections. If you do need to make HTTPS connections to a local server, for example to test an HTTPS-only service, you will need to create and use your own certificates. Here's one way to do it: Use trustme-cli to generate a pair of server key/cert files, and a client cert file. Pass the server key/cert files when starting your local server. (This depends on the particular web server you're using. For example, Uvicorn provides the --ssl-keyfile and --ssl-certfile options.) Tell HTTPX to use the certificates stored in client.pem : >>> import httpx >>> r = httpx . get ( \"https://localhost:8000\" , verify = \"/tmp/client.pem\" ) >>> r Response < 200 OK >","title":"Advanced Usage"},{"location":"advanced/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"advanced/#client-instances","text":"Using a Client instance to make requests will give you HTTP connection pooling, will provide cookie persistence, and allows you to apply configuration across all outgoing requests. Hint A Client instance is equivalent to a Session instance in requests . Note Starting from httpx==0.10.0 , the default and recommended Client class is AsyncClient . This should help prevent breaking changes once sync support is reintroduced. A Client synonym remains for compatibility with httpx==0.9.* releases, but you are encouraged to migrate to AsyncClient as soon as possible.","title":"Client Instances"},{"location":"advanced/#usage","text":"The recommended way to use a Client is as a context manager. This will ensure that connections are properly cleaned up when leaving the with block: >>> with httpx . Client () as client : ... r = client . get ( 'https://example.com' ) ... >>> r < Response [ 200 OK ] > Alternatively, you can explicitly close the connection pool without block-usage using .close() : >>> client = httpx . Client () >>> try : ... r = client . get ( 'https://example.com' ) ... finally : ... client . close () ... >>> r < Response [ 200 OK ] > Once you have a Client , you can use all the features documented in the Quickstart guide.","title":"Usage"},{"location":"advanced/#configuration","text":"Clients allow you to apply configuration to all outgoing requests by passing parameters to the Client constructor. For example, to apply a set of custom headers on every request: >>> url = 'http://httpbin.org/headers' >>> headers = { 'user-agent' : 'my-app/0.0.1' } >>> with httpx . Client ( headers = headers ) as client : ... r = client . get ( url ) ... >>> r . json ()[ 'headers' ][ 'User-Agent' ] 'my-app/0.0.1' Note When you provide a parameter at both the client and request levels, one of two things can happen: For headers, query parameters and cookies, the values are merged into one. For all other parameters, the request-level value is used. Additionally, Client accepts some parameters that aren't available at the request level. One particularly useful parameter is base_url , which allows you to define a base URL to prepend to all outgoing requests: >>> with httpx . Client ( base_url = 'http://httpbin.org' ) as client : ... r = client . get ( '/headers' ) ... >>> r . request . url URL ( 'http://httpbin.org/headers' ) For a list of all available client-level parameters, see the Client API reference .","title":"Configuration"},{"location":"advanced/#calling-into-python-web-apps","text":"You can configure an httpx client to call directly into a Python web application using the WSGI protocol. This is particularly useful for two main use-cases: Using httpx as a client inside test cases. Mocking out external services during tests or in dev/staging environments. Here's an example of integrating against a Flask application: from flask import Flask import httpx app = Flask ( __name__ ) @app . route ( \"/\" ) def hello (): return \"Hello World!\" with httpx . Client ( app = app , base_url = \"http://testserver\" ) as client : r = client . get ( \"/\" ) assert r . status_code == 200 assert r . text == \"Hello World!\" For some more complex cases you might need to customize the WSGI dispatch. This allows you to: Inspect 500 error responses rather than raise exceptions by setting raise_app_exceptions=False . Mount the WSGI application at a subpath by setting script_name (WSGI). Use a given client address for requests by setting remote_addr (WSGI). For example: # Instantiate a client that makes WSGI requests with a client IP of \"1.2.3.4\". dispatch = httpx . WSGIDispatch ( app = app , remote_addr = \"1.2.3.4\" ) with httpx . Client ( dispatch = dispatch , base_url = \"http://testserver\" ) as client : ...","title":"Calling into Python Web Apps"},{"location":"advanced/#build-request","text":"You can use Client.build_request() to build a request and make modifications before sending the request. >>> with httpx . Client () as client : ... req = client . build_request ( \"OPTIONS\" , \"https://example.com\" ) ... req . url . full_path = \"*\" # Build an 'OPTIONS *' request for CORS ... r = client . send ( req ) ... >>> r < Response [ 200 OK ] >","title":"Build Request"},{"location":"advanced/#netrc-support","text":"HTTPX supports .netrc file. In trust_env=True cases, if auth parameter is not defined, HTTPX tries to add auth into request's header from .netrc file. Note The NETRC file is cached across requests made by a client. If you need to refresh the cache (e.g. because the NETRC file has changed), you should create a new client or restart the interpreter. As default trust_env is true. To set false: >>> httpx . get ( 'https://example.org/' , trust_env = False ) If NETRC environment is empty, HTTPX tries to use default files. ( ~/.netrc , ~/_netrc ) To change NETRC environment: >>> import os >>> os . environ [ \"NETRC\" ] = \"my_default_folder/.my_netrc\" .netrc file content example: machine netrcexample . org login example - username password example - password ... When using Client instances, trust_env should be set on the client itself, rather that on the request methods: client = httpx . Client ( trust_env = False )","title":".netrc Support"},{"location":"advanced/#http-proxying","text":"HTTPX supports setting up HTTP proxies the same way that Requests does via the proxies parameter. For example to forward all HTTP traffic to http://127.0.0.1:3080 and all HTTPS traffic to http://127.0.0.1:3081 your proxies config would look like this: >>> proxies = { ... \"http\" : \"http://127.0.0.1:3080\" , ... \"https\" : \"http://127.0.0.1:3081\" ... } >>> with httpx . Client ( proxies = proxies ) as client : ... ... Credentials may be passed in as part of the URL in the standard way, i.e. http://username:password@127.0.0.1:3080 . Proxies can be configured for a specific scheme and host, all schemes of a host, all hosts for a scheme, or for all requests. When determining which proxy configuration to use for a given request this same order is used. >>> proxies = { ... \"http://example.com\" : \"...\" , # Host+Scheme ... \"all://example.com\" : \"...\" , # Host ... \"http\" : \"...\" , # Scheme ... \"all\" : \"...\" , # All ... } >>> with httpx . Client ( proxies = proxies ) as client : ... ... ... >>> proxy = \"...\" # Shortcut for {'all': '...'} >>> with httpx . Client ( proxies = proxy ) as client : ... ... Warning To make sure that proxies cannot read your traffic, and even if the proxy_url uses HTTPS, it is recommended to use HTTPS and tunnel requests if possible. By default httpx.Proxy will operate as a forwarding proxy for http://... requests and will establish a CONNECT TCP tunnel for https:// requests. This doesn't change regardless of the proxy url being http or https . Proxies can be configured to have different behavior such as forwarding or tunneling all requests: proxy = httpx . Proxy ( url = \"https://127.0.0.1\" , mode = \"TUNNEL_ONLY\" # May be \"TUNNEL_ONLY\" or \"FORWARD_ONLY\". Defaults to \"DEFAULT\". ) with httpx . Client ( proxies = proxy ) as client : # This request will be tunneled instead of forwarded. r = client . get ( \"http://example.com\" ) Note To use proxies you must pass the proxy information at Client initialization, rather than on the .get(...) call or other request methods. SOCKS proxies are not supported yet.","title":"HTTP Proxying"},{"location":"advanced/#timeout-configuration","text":"HTTPX is careful to enforce timeouts everywhere by default. The default behavior is to raise a TimeoutException after 5 seconds of network inactivity.","title":"Timeout Configuration"},{"location":"advanced/#setting-and-disabling-timeouts","text":"You can set timeouts for an individual request: # Using the top-level API: httpx . get ( 'http://example.com/api/v1/example' , timeout = 10.0 ) # Using a client instance: with httpx . Client () as client : client . get ( \"http://example.com/api/v1/example\" , timeout = 10.0 ) Or disable timeouts for an individual request: # Using the top-level API: httpx . get ( 'http://example.com/api/v1/example' , timeout = None ) # Using a client instance: with httpx . Client () as client : client . get ( \"http://example.com/api/v1/example\" , timeout = None )","title":"Setting and disabling timeouts"},{"location":"advanced/#setting-a-default-timeout-on-a-client","text":"You can set a timeout on a client instance, which results in the given timeout being used as the default for requests made with this client: client = httpx . Client () # Use a default 5s timeout everywhere. client = httpx . Client ( timeout = 10.0 ) # Use a default 10s timeout everywhere. client = httpx . Client ( timeout = None ) # Disable all timeouts by default.","title":"Setting a default timeout on a client"},{"location":"advanced/#fine-tuning-the-configuration","text":"HTTPX also allows you to specify the timeout behavior in more fine grained detail. There are four different types of timeouts that may occur. These are connect , read , write , and pool timeouts. The connect timeout specifies the maximum amount of time to wait until a connection to the requested host is established. If HTTPX is unable to connect within this time frame, a ConnectTimeout exception is raised. The read timeout specifies the maximum duration to wait for a chunk of data to be received (for example, a chunk of the response body). If HTTPX is unable to receive data within this time frame, a ReadTimeout exception is raised. The write timeout specifies the maximum duration to wait for a chunk of data to be sent (for example, a chunk of the request body). If HTTPX is unable to send data within this time frame, a WriteTimeout exception is raised. The pool timeout specifies the maximum duration to wait for acquiring a connection from the connection pool. If HTTPX is unable to acquire a connection within this time frame, a PoolTimeout exception is raised. A related configuration here is the maximum number of allowable connections in the connection pool, which is configured by the pool_limits . You can configure the timeout behavior for any of these values... # A client with a 60s timeout for connecting, and a 10s timeout elsewhere. timeout = httpx . Timeout ( 10.0 , connect_timeout = 60.0 ) client = httpx . Client ( timeout = timeout ) response = client . get ( 'http://example.com/' )","title":"Fine tuning the configuration"},{"location":"advanced/#multipart-file-encoding","text":"As mentioned in the quickstart multipart file encoding is available by passing a dictionary with the name of the payloads as keys and either tuple of elements or a file-like object or a string as values. >>> files = { 'upload-file' : ( 'report.xls' , open ( 'report.xls' , 'rb' ), 'application/vnd.ms-excel' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } More specifically, if a tuple is used as a value, it must have between 2 and 3 elements: The first element is an optional file name which can be set to None . The second element may be a file-like object or a string which will be automatically encoded in UTF-8. An optional third element can be used to specify the MIME type of the file being uploaded. If not specified HTTPX will attempt to guess the MIME type based on the file name, with unknown file extensions defaulting to \"application/octet-stream\". If the file name is explicitly set to None then HTTPX will not include a content-type MIME header field. >>> files = { 'upload-file' : ( None , 'text content' , 'text/plain' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : {}, \"form\" : { \"upload-file\" : \"text-content\" }, ... }","title":"Multipart file encoding"},{"location":"advanced/#customizing-authentication","text":"When issuing requests or instantiating a client, the auth argument can be used to pass an authentication scheme to use. The auth argument may be one of the following... A two-tuple of username / password , to be used with basic authentication. An instance of httpx.BasicAuth() or httpx.DigestAuth() . A callable, accepting a request and returning an authenticated request instance. A subclass of httpx.Auth . The most involved of these is the last, which allows you to create authentication flows involving one or more requests. A subclass of httpx.Auth should implement def auth_flow(request) , and yield any requests that need to be made... class MyCustomAuth ( httpx . Auth ): def __init__ ( self , token ): self . token = token def auth_flow ( self , request ): # Send the request, with a custom `X-Authentication` header. request . headers [ 'X-Authentication' ] = self . token yield request If the auth flow requires more that one request, you can issue multiple yields, and obtain the response in each case... class MyCustomAuth ( httpx . Auth ): def __init__ ( self , token ): self . token = token def auth_flow ( self , request ): response = yield request if response . status_code == 401 : # If the server issues a 401 response then resend the request, # with a custom `X-Authentication` header. request . headers [ 'X-Authentication' ] = self . token yield request Custom authentication classes are designed to not perform any I/O, so that they may be used with both sync and async client instances. If you are implementing an authentication scheme that requires the request body, then you need to indicate this on the class using a requires_request_body property. You will then be able to access request.content inside the .auth_flow() method. class MyCustomAuth ( httpx . Auth ): requires_request_body = True def __init__ ( self , token ): self . token = token def auth_flow ( self , request ): response = yield request if response . status_code == 401 : # If the server issues a 401 response then resend the request, # with a custom `X-Authentication` header. request . headers [ 'X-Authentication' ] = self . sign_request ( ... ) yield request def sign_request ( self , request ): # Create a request signature, based on `request.method`, `request.url`, # `request.headers`, and `request.content`. ... Similarly, if you are implementing a scheme that requires access to the response body, then use the requires_response_body property. You will then be able to access response body properties and methods such as response.content , response.text , response.json() , etc. class MyCustomAuth ( httpx . Auth ): requires_response_body = True def __init__ ( self , access_token , refresh_token , refresh_url ): self . access_token = access_token self . refresh_token = refresh_token self . refresh_url = refresh_url def auth_flow ( self , request ): request . headers [ \"X-Authentication\" ] = self . access_token response = yield request if response . status_code == 401 : # If the server issues a 401 response, then issue a request to # refresh tokens, and resend the request. refresh_response = yield self . build_refresh_request () self . update_tokens ( refresh_response ) request . headers [ \"X-Authentication\" ] = self . access_token yield request def build_refresh_request ( self ): # Return an `httpx.Request` for refreshing tokens. ... def update_tokens ( self , response ): # Update the `.access_token` and `.refresh_token` tokens # based on a refresh response. data = response . json () ...","title":"Customizing authentication"},{"location":"advanced/#ssl-certificates","text":"When making a request over HTTPS, HTTPX needs to verify the identity of the requested host. To do this, it uses a bundle of SSL certificates (a.k.a. CA bundle) delivered by a trusted certificate authority (CA).","title":"SSL certificates"},{"location":"advanced/#changing-the-verification-defaults","text":"By default, HTTPX uses the CA bundle provided by Certifi . This is what you want in most cases, even though some advanced situations may require you to use a different set of certificates. If you'd like to use a custom CA bundle, you can use the verify parameter. import httpx r = httpx . get ( \"https://example.org\" , verify = \"path/to/client.pem\" ) You can also disable the SSL verification... import httpx r = httpx . get ( \"https://example.org\" , verify = False )","title":"Changing the verification defaults"},{"location":"advanced/#ssl-configuration-on-client-instances","text":"If you're using a Client() instance, then you should pass any SSL settings when instantiating the client. client = httpx . Client ( verify = False ) The client.get(...) method and other request methods do not support changing the SSL settings on a per-request basis. If you need different SSL settings in different cases you should use more that one client instance, with different settings on each. Each client will then be using an isolated connection pool with a specific fixed SSL configuration on all connections within that pool.","title":"SSL configuration on client instances"},{"location":"advanced/#making-https-requests-to-a-local-server","text":"When making requests to local servers, such as a development server running on localhost , you will typically be using unencrypted HTTP connections. If you do need to make HTTPS connections to a local server, for example to test an HTTPS-only service, you will need to create and use your own certificates. Here's one way to do it: Use trustme-cli to generate a pair of server key/cert files, and a client cert file. Pass the server key/cert files when starting your local server. (This depends on the particular web server you're using. For example, Uvicorn provides the --ssl-keyfile and --ssl-certfile options.) Tell HTTPX to use the certificates stored in client.pem : >>> import httpx >>> r = httpx . get ( \"https://localhost:8000\" , verify = \"/tmp/client.pem\" ) >>> r Response < 200 OK >","title":"Making HTTPS requests to a local server"},{"location":"api/","text":"Developer Interface Helper Functions Note Only use these functions if you're testing HTTPX in a console or making a small number of requests. Using a Client will enable HTTP/2 and connection pooling for more efficient and long-lived connections. httpx. request ( method , url , * , params=None , data=None , files=None , json=None , headers=None , cookies=None , auth=None , timeout=Timeout(timeout=5.0) , allow_redirects=True , verify=True , cert=None , trust_env=True ) Sends an HTTP request. Parameters: method - HTTP method for the new Request object: GET , OPTIONS , HEAD , POST , PUT , PATCH , or DELETE . url - URL for the new Request object. params - (optional) Query parameters to include in the URL, as a string, dictionary, or list of two-tuples. data - (optional) Data to include in the body of the request, as a dictionary files - (optional) A dictionary of upload files to include in the body of the request. json - (optional) A JSON serializable object to include in the body of the request. headers - (optional) Dictionary of HTTP headers to include in the request. cookies - (optional) Dictionary of Cookie items to include in the request. auth - (optional) An authentication class to use when sending the request. timeout - (optional) The timeout configuration to use when sending the request. allow_redirects - (optional) Enables or disables HTTP redirects. verify - (optional) SSL certificates (a.k.a CA bundle) used to verify the identity of requested hosts. Either True (default CA bundle), a path to an SSL certificate file, or False (disable verification). cert - (optional) An SSL certificate used by the requested host to authenticate the client. Either a path to an SSL certificate file, or two-tuple of (certificate file, key file), or a three-tuple of (certificate file, key file, password). trust_env - (optional) Enables or disables usage of environment variables for configuration. proxies - (optional) A dictionary mapping HTTP protocols to proxy URLs. Returns: Response Usage: >>> import httpx >>> response = httpx . request ( 'GET' , 'https://httpbin.org/get' ) >>> response < Response [ 200 OK ] > httpx. get ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a GET request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as GET requests should not include a request body. httpx. options ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends an OPTIONS request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as OPTIONS requests should not include a request body. httpx. head ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=False , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a HEAD request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as HEAD requests should not include a request body. The HEAD method also differs from the other cases in that allow_redirects defaults to False . httpx. post ( url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a POST request. Parameters : See httpx.request . httpx. put ( url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a PUT request. Parameters : See httpx.request . httpx. patch ( url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a PATCH request. Parameters : See httpx.request . httpx. delete ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a DELETE request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as DELETE requests should not include a request body. Client class httpx. Client ( * , auth=None , params=None , headers=None , cookies=None , verify=True , cert=None , proxies=None , timeout=Timeout(timeout=5.0) , pool_limits=PoolLimits(soft_limit=10, hard_limit=100) , max_redirects=20 , base_url=None , dispatch=None , app=None , trust_env=True ) An HTTP client, with connection pooling, HTTP/2, redirects, cookie persistence, etc. Usage: >>> client = httpx . Client () >>> response = client . get ( 'https://example.org' ) Parameters: auth - (optional) An authentication class to use when sending requests. params - (optional) Query parameters to include in request URLs, as a string, dictionary, or list of two-tuples. headers - (optional) Dictionary of HTTP headers to include when sending requests. cookies - (optional) Dictionary of Cookie items to include when sending requests. verify - (optional) SSL certificates (a.k.a CA bundle) used to verify the identity of requested hosts. Either True (default CA bundle), a path to an SSL certificate file, or False (disable verification). cert - (optional) An SSL certificate used by the requested host to authenticate the client. Either a path to an SSL certificate file, or two-tuple of (certificate file, key file), or a three-tuple of (certificate file, key file, password). proxies - (optional) A dictionary mapping HTTP protocols to proxy URLs. timeout - (optional) The timeout configuration to use when sending requests. pool_limits - (optional) The connection pool configuration to use when determining the maximum number of concurrently open HTTP connections. max_redirects - (optional) The maximum number of redirect responses that should be followed. base_url - (optional) A URL to use as the base when building request URLs. dispatch - (optional) A dispatch class to use for sending requests over the network. app - (optional) An ASGI application to send requests to, rather than sending actual network requests. trust_env - (optional) Enables or disables usage of environment variables for configuration. headers HTTP headers to include when sending requests. cookies Cookie values to include when sending requests. params Query parameters to include in the URL when sending requests. request ( self , method , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) get ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) head ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=False , timeout= ) options ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) post ( self , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) put ( self , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) patch ( self , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) delete ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) build_request ( self , method , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None ) Build and return a request instance. send ( self , request , * , stream=False , auth=None , allow_redirects=True , timeout= ) close ( self ) Response An HTTP response. def __init__(...) .status_code - int .reason_phrase - str .http_version - \"HTTP/2\" or \"HTTP/1.1\" .url - URL .headers - Headers .content - bytes .text - str .encoding - str .is_redirect - bool .request - Request .cookies - Cookies .history - List[Response] .elapsed - timedelta The amount of time elapsed between sending the request and calling close() on the corresponding response received for that request. total_seconds() to correctly get the total elapsed seconds. def .raise_for_status() - None def .json() - Any def .read() - bytes def .iter_raw() - bytes iterator def .iter_bytes() - bytes iterator def .iter_text() - text iterator def .iter_lines() - text iterator def .close() - None def .next() - Response def .aread() - bytes def .aiter_raw() - async bytes iterator def .aiter_bytes() - async bytes iterator def .aiter_text() - async text iterator def .aiter_lines() - async text iterator def .aclose() - None def .anext() - Response Request An HTTP request. Can be constructed explicitly for more control over exactly what gets sent over the wire. >>> request = httpx . Request ( \"GET\" , \"https://example.org\" , headers = { 'host' : 'example.org' }) >>> response = client . send ( request ) def __init__(method, url, [params], [data], [json], [headers], [cookies]) .method - str .url - URL .content - byte , byte iterator , or byte async iterator .headers - Headers .cookies - Cookies URL A normalized, IDNA supporting URL. >>> url = URL ( \"https://example.org/\" ) >>> url . host 'example.org' def __init__(url, allow_relative=False, params=None) .scheme - str .authority - str .host - str .port - int .path - str .query - str .full_path - str .fragment - str .is_ssl - bool .origin - Origin .is_absolute_url - bool .is_relative_url - bool def .copy_with([scheme], [authority], [path], [query], [fragment]) - URL def .resolve_with(url) - URL Origin A normalized, IDNA supporting set of scheme/host/port info. >>> Origin ( 'https://example.org' ) == Origin ( 'HTTPS://EXAMPLE.ORG:443' ) True def __init__(url) .scheme - str .is_ssl - bool .host - str .port - int Headers A case-insensitive multi-dict. >>> headers = Headers ({ 'Content-Type' : 'application/json' }) >>> headers [ 'content-type' ] 'application/json' def __init__(self, headers) Cookies A dict-like cookie store. >>> cookies = Cookies () >>> cookies . set ( \"name\" , \"value\" , domain = \"example.org\" ) def __init__(cookies: [dict, Cookies, CookieJar]) .jar - CookieJar def extract_cookies(response) def set_cookie_header(request) def set(name, value, [domain], [path]) def get(name, [domain], [path]) def delete(name, [domain], [path]) def clear([domain], [path]) Standard mutable mapping interface","title":"Developer Interface"},{"location":"api/#developer-interface","text":"","title":"Developer Interface"},{"location":"api/#helper-functions","text":"Note Only use these functions if you're testing HTTPX in a console or making a small number of requests. Using a Client will enable HTTP/2 and connection pooling for more efficient and long-lived connections. httpx. request ( method , url , * , params=None , data=None , files=None , json=None , headers=None , cookies=None , auth=None , timeout=Timeout(timeout=5.0) , allow_redirects=True , verify=True , cert=None , trust_env=True ) Sends an HTTP request. Parameters: method - HTTP method for the new Request object: GET , OPTIONS , HEAD , POST , PUT , PATCH , or DELETE . url - URL for the new Request object. params - (optional) Query parameters to include in the URL, as a string, dictionary, or list of two-tuples. data - (optional) Data to include in the body of the request, as a dictionary files - (optional) A dictionary of upload files to include in the body of the request. json - (optional) A JSON serializable object to include in the body of the request. headers - (optional) Dictionary of HTTP headers to include in the request. cookies - (optional) Dictionary of Cookie items to include in the request. auth - (optional) An authentication class to use when sending the request. timeout - (optional) The timeout configuration to use when sending the request. allow_redirects - (optional) Enables or disables HTTP redirects. verify - (optional) SSL certificates (a.k.a CA bundle) used to verify the identity of requested hosts. Either True (default CA bundle), a path to an SSL certificate file, or False (disable verification). cert - (optional) An SSL certificate used by the requested host to authenticate the client. Either a path to an SSL certificate file, or two-tuple of (certificate file, key file), or a three-tuple of (certificate file, key file, password). trust_env - (optional) Enables or disables usage of environment variables for configuration. proxies - (optional) A dictionary mapping HTTP protocols to proxy URLs. Returns: Response Usage: >>> import httpx >>> response = httpx . request ( 'GET' , 'https://httpbin.org/get' ) >>> response < Response [ 200 OK ] > httpx. get ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a GET request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as GET requests should not include a request body. httpx. options ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends an OPTIONS request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as OPTIONS requests should not include a request body. httpx. head ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=False , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a HEAD request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as HEAD requests should not include a request body. The HEAD method also differs from the other cases in that allow_redirects defaults to False . httpx. post ( url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a POST request. Parameters : See httpx.request . httpx. put ( url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a PUT request. Parameters : See httpx.request . httpx. patch ( url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a PATCH request. Parameters : See httpx.request . httpx. delete ( url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , cert=None , verify=True , timeout=Timeout(timeout=5.0) , trust_env=True ) Sends a DELETE request. Parameters : See httpx.request . Note that the data , files , and json parameters are not available on this function, as DELETE requests should not include a request body.","title":"Helper Functions"},{"location":"api/#client","text":"class httpx. Client ( * , auth=None , params=None , headers=None , cookies=None , verify=True , cert=None , proxies=None , timeout=Timeout(timeout=5.0) , pool_limits=PoolLimits(soft_limit=10, hard_limit=100) , max_redirects=20 , base_url=None , dispatch=None , app=None , trust_env=True ) An HTTP client, with connection pooling, HTTP/2, redirects, cookie persistence, etc. Usage: >>> client = httpx . Client () >>> response = client . get ( 'https://example.org' ) Parameters: auth - (optional) An authentication class to use when sending requests. params - (optional) Query parameters to include in request URLs, as a string, dictionary, or list of two-tuples. headers - (optional) Dictionary of HTTP headers to include when sending requests. cookies - (optional) Dictionary of Cookie items to include when sending requests. verify - (optional) SSL certificates (a.k.a CA bundle) used to verify the identity of requested hosts. Either True (default CA bundle), a path to an SSL certificate file, or False (disable verification). cert - (optional) An SSL certificate used by the requested host to authenticate the client. Either a path to an SSL certificate file, or two-tuple of (certificate file, key file), or a three-tuple of (certificate file, key file, password). proxies - (optional) A dictionary mapping HTTP protocols to proxy URLs. timeout - (optional) The timeout configuration to use when sending requests. pool_limits - (optional) The connection pool configuration to use when determining the maximum number of concurrently open HTTP connections. max_redirects - (optional) The maximum number of redirect responses that should be followed. base_url - (optional) A URL to use as the base when building request URLs. dispatch - (optional) A dispatch class to use for sending requests over the network. app - (optional) An ASGI application to send requests to, rather than sending actual network requests. trust_env - (optional) Enables or disables usage of environment variables for configuration. headers HTTP headers to include when sending requests. cookies Cookie values to include when sending requests. params Query parameters to include in the URL when sending requests. request ( self , method , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) get ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) head ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=False , timeout= ) options ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) post ( self , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) put ( self , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) patch ( self , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) delete ( self , url , * , params=None , headers=None , cookies=None , auth=None , allow_redirects=True , timeout= ) build_request ( self , method , url , * , data=None , files=None , json=None , params=None , headers=None , cookies=None ) Build and return a request instance. send ( self , request , * , stream=False , auth=None , allow_redirects=True , timeout= ) close ( self )","title":"Client"},{"location":"api/#response","text":"An HTTP response. def __init__(...) .status_code - int .reason_phrase - str .http_version - \"HTTP/2\" or \"HTTP/1.1\" .url - URL .headers - Headers .content - bytes .text - str .encoding - str .is_redirect - bool .request - Request .cookies - Cookies .history - List[Response] .elapsed - timedelta The amount of time elapsed between sending the request and calling close() on the corresponding response received for that request. total_seconds() to correctly get the total elapsed seconds. def .raise_for_status() - None def .json() - Any def .read() - bytes def .iter_raw() - bytes iterator def .iter_bytes() - bytes iterator def .iter_text() - text iterator def .iter_lines() - text iterator def .close() - None def .next() - Response def .aread() - bytes def .aiter_raw() - async bytes iterator def .aiter_bytes() - async bytes iterator def .aiter_text() - async text iterator def .aiter_lines() - async text iterator def .aclose() - None def .anext() - Response","title":"Response"},{"location":"api/#request","text":"An HTTP request. Can be constructed explicitly for more control over exactly what gets sent over the wire. >>> request = httpx . Request ( \"GET\" , \"https://example.org\" , headers = { 'host' : 'example.org' }) >>> response = client . send ( request ) def __init__(method, url, [params], [data], [json], [headers], [cookies]) .method - str .url - URL .content - byte , byte iterator , or byte async iterator .headers - Headers .cookies - Cookies","title":"Request"},{"location":"api/#url","text":"A normalized, IDNA supporting URL. >>> url = URL ( \"https://example.org/\" ) >>> url . host 'example.org' def __init__(url, allow_relative=False, params=None) .scheme - str .authority - str .host - str .port - int .path - str .query - str .full_path - str .fragment - str .is_ssl - bool .origin - Origin .is_absolute_url - bool .is_relative_url - bool def .copy_with([scheme], [authority], [path], [query], [fragment]) - URL def .resolve_with(url) - URL","title":"URL"},{"location":"api/#origin","text":"A normalized, IDNA supporting set of scheme/host/port info. >>> Origin ( 'https://example.org' ) == Origin ( 'HTTPS://EXAMPLE.ORG:443' ) True def __init__(url) .scheme - str .is_ssl - bool .host - str .port - int","title":"Origin"},{"location":"api/#headers","text":"A case-insensitive multi-dict. >>> headers = Headers ({ 'Content-Type' : 'application/json' }) >>> headers [ 'content-type' ] 'application/json' def __init__(self, headers)","title":"Headers"},{"location":"api/#cookies","text":"A dict-like cookie store. >>> cookies = Cookies () >>> cookies . set ( \"name\" , \"value\" , domain = \"example.org\" ) def __init__(cookies: [dict, Cookies, CookieJar]) .jar - CookieJar def extract_cookies(response) def set_cookie_header(request) def set(name, value, [domain], [path]) def get(name, [domain], [path]) def delete(name, [domain], [path]) def clear([domain], [path]) Standard mutable mapping interface","title":"Cookies"},{"location":"async/","text":"Async Support HTTPX offers a standard synchronous API by default, but also gives you the option of an async client if you need it. Async is a concurrency model that is far more efficient than multi-threading, and can provide significant performance benefits and enable the use of long-lived network connections such as WebSockets. If you're working with an async web framework then you'll also want to use an async client for sending outgoing HTTP requests. Making Async requests To make asynchronous requests, you'll need an AsyncClient . >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.com/' ) >>> r < Response [ 200 OK ] > Tip Use IPython or Python 3.8+ with python -m asyncio to try this code interactively, as they support executing async / await expressions in the console. API Differences If you're using an async client then there are a few bits of API that use async methods. Making requests The request methods are all async, so you should use response = await client.get(...) style for all of the following: AsyncClient.get(url, ...) AsyncClient.options(url, ...) AsyncClient.head(url, ...) AsyncClient.post(url, ...) AsyncClient.put(url, ...) AsyncClient.patch(url, ...) AsyncClient.delete(url, ...) AsyncClient.request(method, url, ...) AsyncClient.send(request, ...) Opening and closing clients Use async with httpx.AsyncClient() if you want a context-managed client... async with httpx . AsyncClient () as client : ... Alternatively, use await client.aclose() if you want to close a client explicitly: client = httpx . AsyncClient () ... await client . aclose () Streaming responses The AsyncClient.stream(method, url, ...) method is an async context block. >>> client = httpx . AsyncClient () >>> async with client . stream ( 'GET' , 'https://www.example.com/' ) as response : >>> async for chunk in response . aiter_bytes (): >>> ... The async response streaming methods are: Response.aread() - For conditionally reading a response inside a stream block. Response.aiter_bytes() - For streaming the response content as bytes. Response.aiter_text() - For streaming the response content as text. Response.aiter_lines() - For streaming the response content as lines of text. Response.aiter_raw() - For streaming the raw response bytes, without applying content decoding. Response.aclose() - For closing the response. You don't usually need this, since .stream block close the response automatically on exit. Streaming requests When sending a streaming request body with an AsyncClient instance, you should use an async bytes generator instead of a bytes generator: async def upload_bytes (): ... # yield byte content await client . post ( url , data = upload_bytes ()) Supported async environments HTTPX supports either asyncio or trio as an async environment. By default it will auto-detect which of those two to use as the backend for socket operations and concurrency primitives. You can also explicitly select a backend by instantiating a client with the backend argument... client = httpx . AsyncClient ( backend = 'auto' ) # Autodetection. The default case. client = httpx . AsyncClient ( backend = 'asyncio' ) # Use asyncio as the backend. client = httpx . AsyncClient ( backend = 'trio' ) # Use trio as the backend. AsyncIO AsyncIO is Python's built-in library for writing concurrent code with the async/await syntax. import asyncio import httpx async def main (): async with httpx . AsyncClient () as client : response = await client . get ( 'https://www.example.com/' ) print ( response ) asyncio . run ( main ()) Trio Trio is an alternative async library , designed around the the principles of structured concurrency . import httpx import trio async def main (): async with httpx . AsyncClient () as client : response = await client . get ( 'https://www.example.com/' ) print ( response ) trio . run ( main ) Important The trio package must be installed to use the Trio backend. Calling into Python Web Apps Just as httpx.Client allows you to call directly into WSGI web applications, the httpx.AsyncClient class allows you to call directly into ASGI web applications. Let's take this Starlette application as an example: from starlette.applications import Starlette from starlette.responses import HTMLResponse from starlette.routing import Route async def hello (): return HTMLResponse ( \"Hello World!\" ) app = Starlette ( routes = [ Route ( \"/\" , hello )]) We can make requests directly against the application, like so: >>> import httpx >>> async with httpx . AsyncClient ( app = app , base_url = \"http://testserver\" ) as client : ... r = await client . get ( \"/\" ) ... assert r . status_code == 200 ... assert r . text == \"Hello World!\" For some more complex cases you might need to customise the ASGI dispatch. This allows you to: Inspect 500 error responses rather than raise exceptions by setting raise_app_exceptions=False . Mount the ASGI application at a subpath by setting root_path . Use a given client address for requests by setting client . For example: # Instantiate a client that makes ASGI requests with a client IP of \"1.2.3.4\", # on port 123. dispatch = httpx . ASGIDispatch ( app = app , client = ( \"1.2.3.4\" , 123 )) async with httpx . AsyncClient ( dispatch = dispatch , base_url = \"http://testserver\" ) as client : ... See the ASGI documentation for more details on the client and root_path keys. Unix Domain Sockets The async client provides support for connecting through a unix domain socket via the uds parameter. This is useful when making requests to a server that is bound to a socket file rather than an IP address. Here's an example requesting the Docker Engine API: import httpx async with httpx . AsyncClient ( uds = \"/var/run/docker.sock\" ) as client : # This request will connect through the socket file. resp = await client . get ( \"http://localhost/version\" ) This functionality is not currently available in the synchronous client.","title":"Async Support"},{"location":"async/#async-support","text":"HTTPX offers a standard synchronous API by default, but also gives you the option of an async client if you need it. Async is a concurrency model that is far more efficient than multi-threading, and can provide significant performance benefits and enable the use of long-lived network connections such as WebSockets. If you're working with an async web framework then you'll also want to use an async client for sending outgoing HTTP requests.","title":"Async Support"},{"location":"async/#making-async-requests","text":"To make asynchronous requests, you'll need an AsyncClient . >>> async with httpx . AsyncClient () as client : >>> r = await client . get ( 'https://www.example.com/' ) >>> r < Response [ 200 OK ] > Tip Use IPython or Python 3.8+ with python -m asyncio to try this code interactively, as they support executing async / await expressions in the console.","title":"Making Async requests"},{"location":"async/#api-differences","text":"If you're using an async client then there are a few bits of API that use async methods.","title":"API Differences"},{"location":"async/#making-requests","text":"The request methods are all async, so you should use response = await client.get(...) style for all of the following: AsyncClient.get(url, ...) AsyncClient.options(url, ...) AsyncClient.head(url, ...) AsyncClient.post(url, ...) AsyncClient.put(url, ...) AsyncClient.patch(url, ...) AsyncClient.delete(url, ...) AsyncClient.request(method, url, ...) AsyncClient.send(request, ...)","title":"Making requests"},{"location":"async/#opening-and-closing-clients","text":"Use async with httpx.AsyncClient() if you want a context-managed client... async with httpx . AsyncClient () as client : ... Alternatively, use await client.aclose() if you want to close a client explicitly: client = httpx . AsyncClient () ... await client . aclose ()","title":"Opening and closing clients"},{"location":"async/#streaming-responses","text":"The AsyncClient.stream(method, url, ...) method is an async context block. >>> client = httpx . AsyncClient () >>> async with client . stream ( 'GET' , 'https://www.example.com/' ) as response : >>> async for chunk in response . aiter_bytes (): >>> ... The async response streaming methods are: Response.aread() - For conditionally reading a response inside a stream block. Response.aiter_bytes() - For streaming the response content as bytes. Response.aiter_text() - For streaming the response content as text. Response.aiter_lines() - For streaming the response content as lines of text. Response.aiter_raw() - For streaming the raw response bytes, without applying content decoding. Response.aclose() - For closing the response. You don't usually need this, since .stream block close the response automatically on exit.","title":"Streaming responses"},{"location":"async/#streaming-requests","text":"When sending a streaming request body with an AsyncClient instance, you should use an async bytes generator instead of a bytes generator: async def upload_bytes (): ... # yield byte content await client . post ( url , data = upload_bytes ())","title":"Streaming requests"},{"location":"async/#supported-async-environments","text":"HTTPX supports either asyncio or trio as an async environment. By default it will auto-detect which of those two to use as the backend for socket operations and concurrency primitives. You can also explicitly select a backend by instantiating a client with the backend argument... client = httpx . AsyncClient ( backend = 'auto' ) # Autodetection. The default case. client = httpx . AsyncClient ( backend = 'asyncio' ) # Use asyncio as the backend. client = httpx . AsyncClient ( backend = 'trio' ) # Use trio as the backend.","title":"Supported async environments"},{"location":"async/#asyncio","text":"AsyncIO is Python's built-in library for writing concurrent code with the async/await syntax. import asyncio import httpx async def main (): async with httpx . AsyncClient () as client : response = await client . get ( 'https://www.example.com/' ) print ( response ) asyncio . run ( main ())","title":"AsyncIO"},{"location":"async/#trio","text":"Trio is an alternative async library , designed around the the principles of structured concurrency . import httpx import trio async def main (): async with httpx . AsyncClient () as client : response = await client . get ( 'https://www.example.com/' ) print ( response ) trio . run ( main ) Important The trio package must be installed to use the Trio backend.","title":"Trio"},{"location":"async/#calling-into-python-web-apps","text":"Just as httpx.Client allows you to call directly into WSGI web applications, the httpx.AsyncClient class allows you to call directly into ASGI web applications. Let's take this Starlette application as an example: from starlette.applications import Starlette from starlette.responses import HTMLResponse from starlette.routing import Route async def hello (): return HTMLResponse ( \"Hello World!\" ) app = Starlette ( routes = [ Route ( \"/\" , hello )]) We can make requests directly against the application, like so: >>> import httpx >>> async with httpx . AsyncClient ( app = app , base_url = \"http://testserver\" ) as client : ... r = await client . get ( \"/\" ) ... assert r . status_code == 200 ... assert r . text == \"Hello World!\" For some more complex cases you might need to customise the ASGI dispatch. This allows you to: Inspect 500 error responses rather than raise exceptions by setting raise_app_exceptions=False . Mount the ASGI application at a subpath by setting root_path . Use a given client address for requests by setting client . For example: # Instantiate a client that makes ASGI requests with a client IP of \"1.2.3.4\", # on port 123. dispatch = httpx . ASGIDispatch ( app = app , client = ( \"1.2.3.4\" , 123 )) async with httpx . AsyncClient ( dispatch = dispatch , base_url = \"http://testserver\" ) as client : ... See the ASGI documentation for more details on the client and root_path keys.","title":"Calling into Python Web Apps"},{"location":"async/#unix-domain-sockets","text":"The async client provides support for connecting through a unix domain socket via the uds parameter. This is useful when making requests to a server that is bound to a socket file rather than an IP address. Here's an example requesting the Docker Engine API: import httpx async with httpx . AsyncClient ( uds = \"/var/run/docker.sock\" ) as client : # This request will connect through the socket file. resp = await client . get ( \"http://localhost/version\" ) This functionality is not currently available in the synchronous client.","title":"Unix Domain Sockets"},{"location":"compatibility/","text":"Requests Compatibility Guide HTTPX aims to be compatible with the requests API wherever possible. This documentation outlines places where the API differs... Request URLs Accessing response.url will return a URL instance, rather than a string. Use str(response.url) if you need a string instance. Status Codes In our documentation we prefer the uppercased versions, such as codes.NOT_FOUND , but also provide lower-cased versions for API compatibility with requests . Requests includes various synonyms for status codes that HTTPX does not support. Streaming responses HTTPX provides a .stream() interface rather than using stream=True . This ensures that streaming responses are always properly closed outside of the stream block, and makes it visually clearer at which points streaming I/O APIs may be used with a response. For example: with request . stream ( \"GET\" , \"https://www.example.com\" ) as response : ... Within a stream() block request data is made available with: .iter_bytes() - Instead of response.iter_content() .iter_text() - Instead of response.iter_content(decode_unicode=True) .iter_lines() - Corresponding to response.iter_lines() .iter_raw() - Use this instead of response.raw .read() - Read the entire response body, making request.text and response.content available. SSL configuration When using a Client instance, the trust_env , verify , and cert arguments should always be passed on client instantiation, rather than passed to the request method. If you need more than one different SSL configuration, you should use different client instances for each SSL configuration. Request body on HTTP methods The HTTP GET , DELETE , HEAD , and OPTIONS methods are specified as not supporting a request body. To stay in line with this, the .get , .delete , .head and .options functions do not support files , data , or json arguments. If you really do need to send request data using these http methods you should use the generic .request function instead. Checking for 4xx/5xx responses We don't support response.is_ok since the naming is ambiguous there, and might incorrectly imply an equivalence to response.status_code == codes.OK . Instead we provide the response.is_error property. Use if not response.is_error: instead of if response.is_ok: . Client instances The HTTPX equivalent of requests.Session is httpx.Client . session = requests . Session ( ** kwargs ) is generally equivalent to client = httpx . Client ( ** kwargs ) Mocking If you need to mock HTTPX the same way that test utilities like responses and requests-mock does for requests , see RESPX .","title":"Requests Compatibility"},{"location":"compatibility/#requests-compatibility-guide","text":"HTTPX aims to be compatible with the requests API wherever possible. This documentation outlines places where the API differs...","title":"Requests Compatibility Guide"},{"location":"compatibility/#request-urls","text":"Accessing response.url will return a URL instance, rather than a string. Use str(response.url) if you need a string instance.","title":"Request URLs"},{"location":"compatibility/#status-codes","text":"In our documentation we prefer the uppercased versions, such as codes.NOT_FOUND , but also provide lower-cased versions for API compatibility with requests . Requests includes various synonyms for status codes that HTTPX does not support.","title":"Status Codes"},{"location":"compatibility/#streaming-responses","text":"HTTPX provides a .stream() interface rather than using stream=True . This ensures that streaming responses are always properly closed outside of the stream block, and makes it visually clearer at which points streaming I/O APIs may be used with a response. For example: with request . stream ( \"GET\" , \"https://www.example.com\" ) as response : ... Within a stream() block request data is made available with: .iter_bytes() - Instead of response.iter_content() .iter_text() - Instead of response.iter_content(decode_unicode=True) .iter_lines() - Corresponding to response.iter_lines() .iter_raw() - Use this instead of response.raw .read() - Read the entire response body, making request.text and response.content available.","title":"Streaming responses"},{"location":"compatibility/#ssl-configuration","text":"When using a Client instance, the trust_env , verify , and cert arguments should always be passed on client instantiation, rather than passed to the request method. If you need more than one different SSL configuration, you should use different client instances for each SSL configuration.","title":"SSL configuration"},{"location":"compatibility/#request-body-on-http-methods","text":"The HTTP GET , DELETE , HEAD , and OPTIONS methods are specified as not supporting a request body. To stay in line with this, the .get , .delete , .head and .options functions do not support files , data , or json arguments. If you really do need to send request data using these http methods you should use the generic .request function instead.","title":"Request body on HTTP methods"},{"location":"compatibility/#checking-for-4xx5xx-responses","text":"We don't support response.is_ok since the naming is ambiguous there, and might incorrectly imply an equivalence to response.status_code == codes.OK . Instead we provide the response.is_error property. Use if not response.is_error: instead of if response.is_ok: .","title":"Checking for 4xx/5xx responses"},{"location":"compatibility/#client-instances","text":"The HTTPX equivalent of requests.Session is httpx.Client . session = requests . Session ( ** kwargs ) is generally equivalent to client = httpx . Client ( ** kwargs )","title":"Client instances"},{"location":"compatibility/#mocking","text":"If you need to mock HTTPX the same way that test utilities like responses and requests-mock does for requests , see RESPX .","title":"Mocking"},{"location":"contributing/","text":"Contributing Thank you for being interested in contributing to HTTPX. There are many ways you can contribute to the project: Try HTTPX and report bugs/issues you find Implement new features Review Pull Requests of others Write documentation Participate in discussions Reporting Bugs or Other Issues Found something that HTTPX should support? Stumbled upon some unexpected behavior? Feel free to open an issue at the issue tracker . Try to be more descriptive as you can and in case of a bug report, provide as much information as possible like: OS platform Python version Installed dependencies and versions ( python -m pip freeze ) Code snippet Error traceback Development To start developing HTTPX create a fork of the HTTPX repository on GitHub. Then clone your fork with the following command replacing YOUR-USERNAME with your GitHub username: $ git clone https://github.com/YOUR-USERNAME/httpx You can now install the project and its dependencies using: $ cd httpx $ scripts/install Testing and Linting We use custom shell scripts to automate testing, linting, and documentation building workflow. To run the tests, use: $ scripts/test Warning The test suite spawns testing servers on ports 8000 and 8001 . Make sure these are not in use, so the tests can run properly. You can run a single test script like this: $ scripts/test -- tests/test_multipart.py To run the code auto-formatting: $ scripts/lint Lastly, to run code checks separately (they are also run as part of scripts/test ), run: $ scripts/check Documenting Documentation pages are located under the docs/ folder. To run the documentation site locally (useful for previewing changes), use: $ scripts/docs-serve Resolving Build / Travis Failures Once you've submitted your pull request, the test suite will automatically run, and the results will show up in GitHub. If the test suite fails, you'll want to click through to the \"Details\" link, and try to identify why the test suite failed. Here are some common ways the test suite can fail: Check Job Failed This job failing means there is either a code formatting issue or type-annotation issue. You can look at the job output to figure out why it's failed or within a shell run: $ scripts/check It may be worth it to run $ scripts/lint to attempt auto-formatting the code and if that job succeeds commit the changes. Docs Job Failed This job failing means the documentation failed to build. This can happen for a variety of reasons like invalid markdown or missing configuration within mkdocs.yml . Python 3.X Job Failed This job failing means the unit tests failed or not all code paths are covered by unit tests. If tests are failing you will see this message under the coverage report: === 1 failed, 435 passed, 1 skipped, 1 xfailed in 11.09s === If tests succeed but coverage isn't 100% you will see this message under the coverage report: FAIL Required test coverage of 100% not reached. Total coverage: 99.00% Look at the coverage report from codecov for the pull request for help debugging coverage. Releasing This section is targeted at HTTPX maintainers. Before releasing a new version, create a pull request that includes: An update to the changelog : We follow the format from keepachangelog . Compare master with the tag of the latest release, and list all entries that are of interest to our users: Things that must go in the changelog: added, changed, deprecated or removed features, and bug fixes. Things that should not go in the changelog: changes to documentation, tests or tooling. Try sorting entries in descending order of impact / importance. Keep it concise and to-the-point. \ud83c\udfaf A version bump : see __version__.py . For an example, see #362 . Once the release PR is merged, run $ scripts/publish to publish the new release to PyPI.","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for being interested in contributing to HTTPX. There are many ways you can contribute to the project: Try HTTPX and report bugs/issues you find Implement new features Review Pull Requests of others Write documentation Participate in discussions","title":"Contributing"},{"location":"contributing/#reporting-bugs-or-other-issues","text":"Found something that HTTPX should support? Stumbled upon some unexpected behavior? Feel free to open an issue at the issue tracker . Try to be more descriptive as you can and in case of a bug report, provide as much information as possible like: OS platform Python version Installed dependencies and versions ( python -m pip freeze ) Code snippet Error traceback","title":"Reporting Bugs or Other Issues"},{"location":"contributing/#development","text":"To start developing HTTPX create a fork of the HTTPX repository on GitHub. Then clone your fork with the following command replacing YOUR-USERNAME with your GitHub username: $ git clone https://github.com/YOUR-USERNAME/httpx You can now install the project and its dependencies using: $ cd httpx $ scripts/install","title":"Development"},{"location":"contributing/#testing-and-linting","text":"We use custom shell scripts to automate testing, linting, and documentation building workflow. To run the tests, use: $ scripts/test Warning The test suite spawns testing servers on ports 8000 and 8001 . Make sure these are not in use, so the tests can run properly. You can run a single test script like this: $ scripts/test -- tests/test_multipart.py To run the code auto-formatting: $ scripts/lint Lastly, to run code checks separately (they are also run as part of scripts/test ), run: $ scripts/check","title":"Testing and Linting"},{"location":"contributing/#documenting","text":"Documentation pages are located under the docs/ folder. To run the documentation site locally (useful for previewing changes), use: $ scripts/docs-serve","title":"Documenting"},{"location":"contributing/#resolving-build-travis-failures","text":"Once you've submitted your pull request, the test suite will automatically run, and the results will show up in GitHub. If the test suite fails, you'll want to click through to the \"Details\" link, and try to identify why the test suite failed. Here are some common ways the test suite can fail:","title":"Resolving Build / Travis Failures"},{"location":"contributing/#check-job-failed","text":"This job failing means there is either a code formatting issue or type-annotation issue. You can look at the job output to figure out why it's failed or within a shell run: $ scripts/check It may be worth it to run $ scripts/lint to attempt auto-formatting the code and if that job succeeds commit the changes.","title":"Check Job Failed"},{"location":"contributing/#docs-job-failed","text":"This job failing means the documentation failed to build. This can happen for a variety of reasons like invalid markdown or missing configuration within mkdocs.yml .","title":"Docs Job Failed"},{"location":"contributing/#python-3x-job-failed","text":"This job failing means the unit tests failed or not all code paths are covered by unit tests. If tests are failing you will see this message under the coverage report: === 1 failed, 435 passed, 1 skipped, 1 xfailed in 11.09s === If tests succeed but coverage isn't 100% you will see this message under the coverage report: FAIL Required test coverage of 100% not reached. Total coverage: 99.00% Look at the coverage report from codecov for the pull request for help debugging coverage.","title":"Python 3.X Job Failed"},{"location":"contributing/#releasing","text":"This section is targeted at HTTPX maintainers. Before releasing a new version, create a pull request that includes: An update to the changelog : We follow the format from keepachangelog . Compare master with the tag of the latest release, and list all entries that are of interest to our users: Things that must go in the changelog: added, changed, deprecated or removed features, and bug fixes. Things that should not go in the changelog: changes to documentation, tests or tooling. Try sorting entries in descending order of impact / importance. Keep it concise and to-the-point. \ud83c\udfaf A version bump : see __version__.py . For an example, see #362 . Once the release PR is merged, run $ scripts/publish to publish the new release to PyPI.","title":"Releasing"},{"location":"environment_variables/","text":"Environment Variables The HTTPX library can be configured via environment variables. Environment variables are used by default. To ignore environment variables, trust_env has to be set False . There are two ways to set trust_env to disable environment variables: On the client via httpx.Client(trust_env=False) . Using the top-level API, such as httpx.get(\"<url>\", trust_env=False) . Here is a list of environment variables that HTTPX recognizes and what function they serve: HTTPX_LOG_LEVEL Valid values: debug , trace (case-insensitive) If set to debug , then HTTP requests will be logged to stderr . This is useful for general purpose reporting of network activity. If set to trace , then low-level details about the execution of HTTP requests will be logged to stderr , in addition to debug log lines. This can help you debug issues and see what's exactly being sent over the wire and to which location. Example: # test_script.py import httpx with httpx . Client () as client : r = client . get ( \"https://google.com\" ) Debug output: $ HTTPX_LOG_LEVEL = debug python test_script.py DEBUG [2019-11-06 19:11:24] httpx._client - HTTP Request: GET https://google.com \"HTTP/1.1 301 Moved Permanently\" DEBUG [2019-11-06 19:11:24] httpx._client - HTTP Request: GET https://www.google.com/ \"HTTP/1.1 200 OK\" Trace output: $ HTTPX_LOG_LEVEL = trace python test_script.py TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - acquire_connection origin=Origin(scheme='https' host='google.com' port=443) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - new_connection connection=HTTPConnection(origin=Origin(scheme='https' host='google.com' port=443)) TRACE [2019-11-06 19:18:56] httpx._config - load_ssl_context verify=True cert=None trust_env=True http_versions=HTTPVersionConfig(['HTTP/1.1', 'HTTP/2']) TRACE [2019-11-06 19:18:56] httpx._config - load_verify_locations cafile=/Users/florimond/Developer/python-projects/httpx/venv/lib/python3.8/site-packages/certifi/cacert.pem TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - start_connect host='google.com' port=443 timeout=Timeout(timeout=5.0) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - connected http_version='HTTP/2' TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - send_headers stream_id=1 method='GET' target='/' headers=[(b':method', b'GET'), (b':authority', b'google.com'), (b':scheme', b'https'), (b':path', b'/'), (b'user-agent', b'python-httpx/0.7.6'), (b'accept', b'*/*'), (b'accept-encoding', b'gzip, deflate, br'), (b'connection', b'keep-alive')] TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - end_stream stream_id=1 TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<RemoteSettingsChanged changed_settings:{ChangedSetting(setting=SettingCodes.MAX_CONCURRENT_STREAMS, original_value=None, new_value=100), ChangedSetting(setting=SettingCodes.INITIAL_WINDOW_SIZE, original_value=65535, new_value=1048576), ChangedSetting(setting=SettingCodes.MAX_HEADER_LIST_SIZE, original_value=None, new_value=16384)}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<WindowUpdated stream_id:0, delta:983041> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<SettingsAcknowledged changed_settings:{}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<ResponseReceived stream_id:1, headers:[(b':status', b'301'), (b'location', b'https://www.google.com/'), (b'content-type', b'text/html; charset=UTF-8'), (b'date', b'Wed, 06 Nov 2019 18:18:56 GMT'), (b'expires', b'Fri, 06 Dec 2019 18:18:56 GMT'), (b'cache-control', b'public, max-age=2592000'), (b'server', b'gws'), (b'content-length', b'220'), (b'x-xss-protection', b'0'), (b'x-frame-options', b'SAMEORIGIN'), (b'alt-svc', b'quic=\":443\"; ma=2592000; v=\"46,43\",h3-Q050=\":443\"; ma=2592000,h3-Q049=\":443\"; ma=2592000,h3-Q048=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000')]> DEBUG [2019-11-06 19:18:56] httpx._client - HTTP Request: GET https://google.com \"HTTP/2 301 Moved Permanently\" TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - acquire_connection origin=Origin(scheme='https' host='www.google.com' port=443) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - new_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) TRACE [2019-11-06 19:18:56] httpx._config - load_ssl_context verify=True cert=None trust_env=True http_versions=HTTPVersionConfig(['HTTP/1.1', 'HTTP/2']) TRACE [2019-11-06 19:18:56] httpx._config - load_verify_locations cafile=/Users/florimond/Developer/python-projects/httpx/venv/lib/python3.8/site-packages/certifi/cacert.pem TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - start_connect host='www.google.com' port=443 timeout=Timeout(timeout=5.0) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - connected http_version='HTTP/2' TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - send_headers stream_id=1 method='GET' target='/' headers=[(b':method', b'GET'), (b':authority', b'www.google.com'), (b':scheme', b'https'), (b':path', b'/'), (b'user-agent', b'python-httpx/0.7.6'), (b'accept', b'*/*'), (b'accept-encoding', b'gzip, deflate, br'), (b'connection', b'keep-alive')] TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - end_stream stream_id=1 TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<RemoteSettingsChanged changed_settings:{ChangedSetting(setting=SettingCodes.MAX_CONCURRENT_STREAMS, original_value=None, new_value=100), ChangedSetting(setting=SettingCodes.INITIAL_WINDOW_SIZE, original_value=65535, new_value=1048576), ChangedSetting(setting=SettingCodes.MAX_HEADER_LIST_SIZE, original_value=None, new_value=16384)}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<WindowUpdated stream_id:0, delta:983041> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<SettingsAcknowledged changed_settings:{}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<ResponseReceived stream_id:1, headers:[(b':status', b'200'), (b'date', b'Wed, 06 Nov 2019 18:18:56 GMT'), (b'expires', b'-1'), (b'cache-control', b'private, max-age=0'), (b'content-type', b'text/html; charset=ISO-8859-1'), (b'p3p', b'CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"'), (b'content-encoding', b'gzip'), (b'server', b'gws'), (b'content-length', b'5073'), (b'x-xss-protection', b'0'), (b'x-frame-options', b'SAMEORIGIN'), (b'set-cookie', b'1P_JAR=2019-11-06-18; expires=Fri, 06-Dec-2019 18:18:56 GMT; path=/; domain=.google.com; SameSite=none'), (b'set-cookie', b'NID=190=m8G9qLxCz2_4HbZI02ON2HTJF4xTvOhoJiS57Hm-OJrNS2eY20LfXMR_u-mLjujeshW5-BTezI69OGpHksT4ZK2TCDsWeU0DF7AmDTjjXFOdj30eIUTpNq7r9aWRvI8UrqiwlIsLkE8Ee3t5PiIiVdSMUcji7dkavGlMUpkMXU8; expires=Thu, 07-May-2020 18:18:56 GMT; path=/; domain=.google.com; HttpOnly'), (b'alt-svc', b'quic=\":443\"; ma=2592000; v=\"46,43\",h3-Q050=\":443\"; ma=2592000,h3-Q049=\":443\"; ma=2592000,h3-Q048=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000')]> DEBUG [2019-11-06 19:18:56] httpx._client - HTTP Request: GET https://www.google.com/ \"HTTP/2 200 OK\" TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:5186, data:1f8b08000000000002ffc55af97adb4692ff3f4f> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:221, data:> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<StreamEnded stream_id:1> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<PingReceived ping_data:0000000000000000> TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - release_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - close_connection SSLKEYLOGFILE Valid values: a filename If this environment variable is set, TLS keys will be appended to the specified file, creating it if it doesn't exist, whenever key material is generated or received. The keylog file is designed for debugging purposes only. Support for SSLKEYLOGFILE requires Python 3.8 and OpenSSL 1.1.1 or newer. Example: # test_script.py import httpx with httpx . AsyncClient () as client : r = client . get ( \"https://google.com\" ) SSLKEYLOGFILE=test.log python test_script.py cat test.log # TLS secrets log file, generated by OpenSSL / Python SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX SSL_CERT_FILE Valid values: a filename if this environment variable is set then HTTPX will load CA certificate from the specified file instead of the default location. Example: SSL_CERT_FILE=/path/to/ca-certs/ca-bundle.crt python -c \"import httpx; httpx.get('https://example.com')\" SSL_CERT_DIR Valid values: a directory if this environment variable is set then HTTPX will load CA certificates from the specified location instead of the default location. Example: SSL_CERT_DIR=/path/to/ca-certs/ python -c \"import httpx; httpx.get('https://example.com')\" HTTP_PROXY , HTTPS_PROXY , ALL_PROXY Valid values: A URL to a proxy Sets the proxy to be used for http , https , or all requests respectively. export HTTP_PROXY = http://127.0.0.1:3080 # This request will be sent through the proxy python -c \"import httpx; httpx.get('http://example.com')\"","title":"Environment Variables"},{"location":"environment_variables/#environment-variables","text":"The HTTPX library can be configured via environment variables. Environment variables are used by default. To ignore environment variables, trust_env has to be set False . There are two ways to set trust_env to disable environment variables: On the client via httpx.Client(trust_env=False) . Using the top-level API, such as httpx.get(\"<url>\", trust_env=False) . Here is a list of environment variables that HTTPX recognizes and what function they serve:","title":"Environment Variables"},{"location":"environment_variables/#httpx_log_level","text":"Valid values: debug , trace (case-insensitive) If set to debug , then HTTP requests will be logged to stderr . This is useful for general purpose reporting of network activity. If set to trace , then low-level details about the execution of HTTP requests will be logged to stderr , in addition to debug log lines. This can help you debug issues and see what's exactly being sent over the wire and to which location. Example: # test_script.py import httpx with httpx . Client () as client : r = client . get ( \"https://google.com\" ) Debug output: $ HTTPX_LOG_LEVEL = debug python test_script.py DEBUG [2019-11-06 19:11:24] httpx._client - HTTP Request: GET https://google.com \"HTTP/1.1 301 Moved Permanently\" DEBUG [2019-11-06 19:11:24] httpx._client - HTTP Request: GET https://www.google.com/ \"HTTP/1.1 200 OK\" Trace output: $ HTTPX_LOG_LEVEL = trace python test_script.py TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - acquire_connection origin=Origin(scheme='https' host='google.com' port=443) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - new_connection connection=HTTPConnection(origin=Origin(scheme='https' host='google.com' port=443)) TRACE [2019-11-06 19:18:56] httpx._config - load_ssl_context verify=True cert=None trust_env=True http_versions=HTTPVersionConfig(['HTTP/1.1', 'HTTP/2']) TRACE [2019-11-06 19:18:56] httpx._config - load_verify_locations cafile=/Users/florimond/Developer/python-projects/httpx/venv/lib/python3.8/site-packages/certifi/cacert.pem TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - start_connect host='google.com' port=443 timeout=Timeout(timeout=5.0) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - connected http_version='HTTP/2' TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - send_headers stream_id=1 method='GET' target='/' headers=[(b':method', b'GET'), (b':authority', b'google.com'), (b':scheme', b'https'), (b':path', b'/'), (b'user-agent', b'python-httpx/0.7.6'), (b'accept', b'*/*'), (b'accept-encoding', b'gzip, deflate, br'), (b'connection', b'keep-alive')] TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - end_stream stream_id=1 TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<RemoteSettingsChanged changed_settings:{ChangedSetting(setting=SettingCodes.MAX_CONCURRENT_STREAMS, original_value=None, new_value=100), ChangedSetting(setting=SettingCodes.INITIAL_WINDOW_SIZE, original_value=65535, new_value=1048576), ChangedSetting(setting=SettingCodes.MAX_HEADER_LIST_SIZE, original_value=None, new_value=16384)}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<WindowUpdated stream_id:0, delta:983041> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<SettingsAcknowledged changed_settings:{}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<ResponseReceived stream_id:1, headers:[(b':status', b'301'), (b'location', b'https://www.google.com/'), (b'content-type', b'text/html; charset=UTF-8'), (b'date', b'Wed, 06 Nov 2019 18:18:56 GMT'), (b'expires', b'Fri, 06 Dec 2019 18:18:56 GMT'), (b'cache-control', b'public, max-age=2592000'), (b'server', b'gws'), (b'content-length', b'220'), (b'x-xss-protection', b'0'), (b'x-frame-options', b'SAMEORIGIN'), (b'alt-svc', b'quic=\":443\"; ma=2592000; v=\"46,43\",h3-Q050=\":443\"; ma=2592000,h3-Q049=\":443\"; ma=2592000,h3-Q048=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000')]> DEBUG [2019-11-06 19:18:56] httpx._client - HTTP Request: GET https://google.com \"HTTP/2 301 Moved Permanently\" TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - acquire_connection origin=Origin(scheme='https' host='www.google.com' port=443) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - new_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) TRACE [2019-11-06 19:18:56] httpx._config - load_ssl_context verify=True cert=None trust_env=True http_versions=HTTPVersionConfig(['HTTP/1.1', 'HTTP/2']) TRACE [2019-11-06 19:18:56] httpx._config - load_verify_locations cafile=/Users/florimond/Developer/python-projects/httpx/venv/lib/python3.8/site-packages/certifi/cacert.pem TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - start_connect host='www.google.com' port=443 timeout=Timeout(timeout=5.0) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - connected http_version='HTTP/2' TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - send_headers stream_id=1 method='GET' target='/' headers=[(b':method', b'GET'), (b':authority', b'www.google.com'), (b':scheme', b'https'), (b':path', b'/'), (b'user-agent', b'python-httpx/0.7.6'), (b'accept', b'*/*'), (b'accept-encoding', b'gzip, deflate, br'), (b'connection', b'keep-alive')] TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - end_stream stream_id=1 TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<RemoteSettingsChanged changed_settings:{ChangedSetting(setting=SettingCodes.MAX_CONCURRENT_STREAMS, original_value=None, new_value=100), ChangedSetting(setting=SettingCodes.INITIAL_WINDOW_SIZE, original_value=65535, new_value=1048576), ChangedSetting(setting=SettingCodes.MAX_HEADER_LIST_SIZE, original_value=None, new_value=16384)}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<WindowUpdated stream_id:0, delta:983041> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<SettingsAcknowledged changed_settings:{}> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<ResponseReceived stream_id:1, headers:[(b':status', b'200'), (b'date', b'Wed, 06 Nov 2019 18:18:56 GMT'), (b'expires', b'-1'), (b'cache-control', b'private, max-age=0'), (b'content-type', b'text/html; charset=ISO-8859-1'), (b'p3p', b'CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"'), (b'content-encoding', b'gzip'), (b'server', b'gws'), (b'content-length', b'5073'), (b'x-xss-protection', b'0'), (b'x-frame-options', b'SAMEORIGIN'), (b'set-cookie', b'1P_JAR=2019-11-06-18; expires=Fri, 06-Dec-2019 18:18:56 GMT; path=/; domain=.google.com; SameSite=none'), (b'set-cookie', b'NID=190=m8G9qLxCz2_4HbZI02ON2HTJF4xTvOhoJiS57Hm-OJrNS2eY20LfXMR_u-mLjujeshW5-BTezI69OGpHksT4ZK2TCDsWeU0DF7AmDTjjXFOdj30eIUTpNq7r9aWRvI8UrqiwlIsLkE8Ee3t5PiIiVdSMUcji7dkavGlMUpkMXU8; expires=Thu, 07-May-2020 18:18:56 GMT; path=/; domain=.google.com; HttpOnly'), (b'alt-svc', b'quic=\":443\"; ma=2592000; v=\"46,43\",h3-Q050=\":443\"; ma=2592000,h3-Q049=\":443\"; ma=2592000,h3-Q048=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000')]> DEBUG [2019-11-06 19:18:56] httpx._client - HTTP Request: GET https://www.google.com/ \"HTTP/2 200 OK\" TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:5186, data:1f8b08000000000002ffc55af97adb4692ff3f4f> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<DataReceived stream_id:1, flow_controlled_length:221, data:> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=1 event=<StreamEnded stream_id:1> TRACE [2019-11-06 19:18:56] httpx._dispatch.http2 - receive_event stream_id=0 event=<PingReceived ping_data:0000000000000000> TRACE [2019-11-06 19:18:56] httpx._dispatch.connection_pool - release_connection connection=HTTPConnection(origin=Origin(scheme='https' host='www.google.com' port=443)) TRACE [2019-11-06 19:18:56] httpx._dispatch.connection - close_connection","title":"HTTPX_LOG_LEVEL"},{"location":"environment_variables/#sslkeylogfile","text":"Valid values: a filename If this environment variable is set, TLS keys will be appended to the specified file, creating it if it doesn't exist, whenever key material is generated or received. The keylog file is designed for debugging purposes only. Support for SSLKEYLOGFILE requires Python 3.8 and OpenSSL 1.1.1 or newer. Example: # test_script.py import httpx with httpx . AsyncClient () as client : r = client . get ( \"https://google.com\" ) SSLKEYLOGFILE=test.log python test_script.py cat test.log # TLS secrets log file, generated by OpenSSL / Python SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX SERVER_HANDSHAKE_TRAFFIC_SECRET XXXX EXPORTER_SECRET XXXX SERVER_TRAFFIC_SECRET_0 XXXX CLIENT_HANDSHAKE_TRAFFIC_SECRET XXXX CLIENT_TRAFFIC_SECRET_0 XXXX","title":"SSLKEYLOGFILE"},{"location":"environment_variables/#ssl_cert_file","text":"Valid values: a filename if this environment variable is set then HTTPX will load CA certificate from the specified file instead of the default location. Example: SSL_CERT_FILE=/path/to/ca-certs/ca-bundle.crt python -c \"import httpx; httpx.get('https://example.com')\"","title":"SSL_CERT_FILE"},{"location":"environment_variables/#ssl_cert_dir","text":"Valid values: a directory if this environment variable is set then HTTPX will load CA certificates from the specified location instead of the default location. Example: SSL_CERT_DIR=/path/to/ca-certs/ python -c \"import httpx; httpx.get('https://example.com')\"","title":"SSL_CERT_DIR"},{"location":"environment_variables/#http_proxy-https_proxy-all_proxy","text":"Valid values: A URL to a proxy Sets the proxy to be used for http , https , or all requests respectively. export HTTP_PROXY = http://127.0.0.1:3080 # This request will be sent through the proxy python -c \"import httpx; httpx.get('http://example.com')\"","title":"HTTP_PROXY, HTTPS_PROXY, ALL_PROXY"},{"location":"http2/","text":"HTTP/2 HTTP/2 is a major new iteration of the HTTP protocol, that provides a far more efficient transport, with potential performance benefits. HTTP/2 does not change the core semantics of the request or response, but alters the way that data is sent to and from the server. Rather that the text format that HTTP/1.1 uses, HTTP/2 is a binary format. The binary format provides full request and response multiplexing, and efficient compression of HTTP headers. The stream multiplexing means that where HTTP/1.1 requires one TCP stream for each concurrent request, HTTP/2 allows a single TCP stream to handle multiple concurrent requests. HTTP/2 also provides support for functionality such as response prioritization, and server push. For a comprehensive guide to HTTP/2 you may want to check out \" HTTP2 Explained \". Enabling HTTP/2 The HTTPX client provides HTTP/2 support, which is currently only available with the async client . HTTP/2 support is not enabled by default, because HTTP/1.1 is a mature, battle-hardened transport layer, and our HTTP/1.1 may be considered the more robust option at this point in time. It is possible that a future version of httpx may enable HTTP/2 support by default. If you're issuing highly concurrent requests you might want to consider trying out our HTTP/2 support. You can do so by instantiating a client with HTTP/2 support enabled: client = httpx . AsyncClient ( http2 = True ) ... You can also instantiate a client as a context manager, to ensure that all HTTP connections are nicely scoped, and will be closed once the context block is exited. async with httpx . AsyncClient ( http2 = True ) as client : ... Inspecting the HTTP version Enabling HTTP/2 support on the client does not necessarily mean that your requests and responses will be transported over HTTP/2, since both the client and the server need to support HTTP/2. If you connect to a server that only supports HTTP/1.1 the client will use a standard HTTP/1.1 connection instead. You can determine which version of the HTTP protocol was used by examining the .http_version property on the response. client = httpx . AsyncClient ( http2 = True ) response = await client . get ( ... ) print ( response . http_version ) # \"HTTP/1.0\", \"HTTP/1.1\", or \"HTTP/2\".","title":"HTTP/2 Support"},{"location":"http2/#http2","text":"HTTP/2 is a major new iteration of the HTTP protocol, that provides a far more efficient transport, with potential performance benefits. HTTP/2 does not change the core semantics of the request or response, but alters the way that data is sent to and from the server. Rather that the text format that HTTP/1.1 uses, HTTP/2 is a binary format. The binary format provides full request and response multiplexing, and efficient compression of HTTP headers. The stream multiplexing means that where HTTP/1.1 requires one TCP stream for each concurrent request, HTTP/2 allows a single TCP stream to handle multiple concurrent requests. HTTP/2 also provides support for functionality such as response prioritization, and server push. For a comprehensive guide to HTTP/2 you may want to check out \" HTTP2 Explained \".","title":"HTTP/2"},{"location":"http2/#enabling-http2","text":"The HTTPX client provides HTTP/2 support, which is currently only available with the async client . HTTP/2 support is not enabled by default, because HTTP/1.1 is a mature, battle-hardened transport layer, and our HTTP/1.1 may be considered the more robust option at this point in time. It is possible that a future version of httpx may enable HTTP/2 support by default. If you're issuing highly concurrent requests you might want to consider trying out our HTTP/2 support. You can do so by instantiating a client with HTTP/2 support enabled: client = httpx . AsyncClient ( http2 = True ) ... You can also instantiate a client as a context manager, to ensure that all HTTP connections are nicely scoped, and will be closed once the context block is exited. async with httpx . AsyncClient ( http2 = True ) as client : ...","title":"Enabling HTTP/2"},{"location":"http2/#inspecting-the-http-version","text":"Enabling HTTP/2 support on the client does not necessarily mean that your requests and responses will be transported over HTTP/2, since both the client and the server need to support HTTP/2. If you connect to a server that only supports HTTP/1.1 the client will use a standard HTTP/1.1 connection instead. You can determine which version of the HTTP protocol was used by examining the .http_version property on the response. client = httpx . AsyncClient ( http2 = True ) response = await client . get ( ... ) print ( response . http_version ) # \"HTTP/1.0\", \"HTTP/1.1\", or \"HTTP/2\".","title":"Inspecting the HTTP version"},{"location":"quickstart/","text":"QuickStart First, start by importing HTTPX: >>> import httpx Now, let\u2019s try to get a webpage. >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r < Response [ 200 OK ] > Similarly, to make an HTTP POST request: >>> r = httpx . post ( 'https://httpbin.org/post' , data = { 'key' : 'value' }) The PUT, DELETE, HEAD, and OPTIONS requests all follow the same style: >>> r = httpx . put ( 'https://httpbin.org/put' , data = { 'key' : 'value' }) >>> r = httpx . delete ( 'https://httpbin.org/delete' ) >>> r = httpx . head ( 'https://httpbin.org/get' ) >>> r = httpx . options ( 'https://httpbin.org/get' ) Passing Parameters in URLs To include URL query parameters in the request, use the params keyword: >>> params = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) To see how the values get encoding into the URL string, we can inspect the resulting URL that was used to make the request: >>> r . url URL ( 'https://httpbin.org/get?key2=value2&key1=value1' ) You can also pass a list of items as a value: >>> params = { 'key1' : 'value1' , 'key2' : [ 'value2' , 'value3' ]} >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) >>> r . url URL ( 'https://httpbin.org/get?key1=value1&key2=value2&key2=value3' ) Response Content HTTPX will automatically handle decoding the response content into Unicode text. >>> r = httpx . get ( 'https://www.example.org/' ) >>> r . text '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' You can inspect what encoding has been used to decode the response. >>> r . encoding 'UTF-8' If you need to override the standard behavior and explicitly set the encoding to use, then you can do that too. >>> r . encoding = 'ISO-8859-1' Binary Response Content The response content can also be accessed as bytes, for non-text responses: >>> r . content b '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' Any gzip and deflate HTTP response encodings will automatically be decoded for you. If brotlipy is installed, then the brotli response encoding will also be supported. For example, to create an image from binary data returned by a request, you can use the following code: >>> from PIL import Image >>> from io import BytesIO >>> i = Image . open ( BytesIO ( r . content )) JSON Response Content Often Web API responses will be encoded as JSON. >>> r = httpx . get ( 'https://api.github.com/events' ) >>> r . json () [{ u 'repository' : { u 'open_issues' : 0 , u 'url' : 'https://github.com/...' ... }}] Custom Headers To include additional headers in the outgoing request, use the headers keyword argument: >>> url = 'http://httpbin.org/headers' >>> headers = { 'user-agent' : 'my-app/0.0.1' } >>> r = httpx . get ( url , headers = headers ) Sending Form Encoded Data Some types of HTTP requests, such as POST and PUT requests, can include data in the request body. One common way of including that is as form-encoded data, which is used for HTML forms. >>> data = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key2\" : \"value2\" , \"key1\" : \"value1\" }, ... } Form encoded data can also include multiple values form a given key. >>> data = { 'key1' : [ 'value1' , 'value2' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key1\" : [ \"value1\" , \"value2\" ] }, ... } Sending Multipart File Uploads You can also upload files, using HTTP multipart encoding: >>> files = { 'upload-file' : open ( 'report.xls' , 'rb' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } You can also explicitly set the filename and content type, by using a tuple of items for the file value: >>> files = { 'upload-file' : ( 'report.xls' , open ( 'report.xls' , 'rb' ), 'application/vnd.ms-excel' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } Sending JSON Encoded Data Form encoded data is okay if all you need is a simple key-value data structure. For more complicated data structures you'll often want to use JSON encoding instead. >>> data = { 'integer' : 123 , 'boolean' : True , 'list' : [ 'a' , 'b' , 'c' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , json = data ) >>> print ( r . text ) { ... \"json\" : { \"boolean\" : true , \"integer\" : 123 , \"list\" : [ \"a\" , \"b\" , \"c\" ] }, ... } Sending Binary Request Data For other encodings, you should use either a bytes type or a generator that yields bytes . You'll probably also want to set a custom Content-Type header when uploading binary data. Response Status Codes We can inspect the HTTP status code of the response: >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r . status_code 200 HTTPX also includes an easy shortcut for accessing status codes by their text phrase. >>> r . status_code == httpx . codes . OK True We can raise an exception for any Client or Server error responses (4xx or 5xx status codes): >>> not_found = httpx . get ( 'https://httpbin.org/status/404' ) >>> not_found . status_code 404 >>> not_found . raise_for_status () Traceback ( most recent call last ): File \"/Users/tomchristie/GitHub/encode/httpcore/httpx/models.py\" , line 776 , in raise_for_status raise HttpError ( message ) httpx . exceptions . HttpError : 404 Not Found Any successful response codes will simply return None rather than raising an exception. >>> r . raise_for_status () Response Headers The response headers are available as a dictionary-like interface. >>> r . headers Headers ({ 'content-encoding' : 'gzip' , 'transfer-encoding' : 'chunked' , 'connection' : 'close' , 'server' : 'nginx/1.0.4' , 'x-runtime' : '148ms' , 'etag' : '\"e1ca502697e5c9317743dc078f67693f\"' , 'content-type' : 'application/json' }) The Headers data type is case-insensitive, so you can use any capitalization. >>> r . headers [ 'Content-Type' ] 'application/json' >>> r . headers . get ( 'content-type' ) 'application/json' Multiple values for a single response header are represented as a single comma-separated value, as per RFC 7230 : A recipient MAY combine multiple header fields with the same field name into one \u201cfield-name: field-value\u201d pair, without changing the semantics of the message, by appending each subsequent field-value to the combined field value in order, separated by a comma. Streaming Responses For large downloads you may want to use streaming responses that do not load the entire response body into memory at once. You can stream the binary content of the response... >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for data in r . iter_bytes (): ... print ( data ) Or the text of the response... >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for text in r . iter_text (): ... print ( text ) Or stream the text, on a line-by-line basis... >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for line in r . iter_lines (): ... print ( line ) HTTPX will use universal line endings, normalising all cases to \\n . In some cases you might want to access the raw bytes on the response without applying any HTTP content decoding. In this case any content encoding that the web server has applied such as gzip , deflate , or brotli will not be automatically decoded. >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for chunk in r . iter_raw (): ... print ( chunk ) If you're using streaming responses in any of these ways then the response.content and response.text attributes will not be available, and will raise errors if accessed. However you can also use the response streaming functionality to conditionally load the response body: >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... if r . headers [ 'Content-Length' ] < TOO_LONG : ... r . read () ... print ( r . text ) Cookies Any cookies that are set on the response can be easily accessed: >>> r = httpx . get ( 'http://httpbin.org/cookies/set?chocolate=chip' , allow_redirects = False ) >>> r . cookies [ 'chocolate' ] 'chip' To include cookies in an outgoing request, use the cookies parameter: >>> cookies = { \"peanut\" : \"butter\" } >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'peanut' : 'butter' }} Cookies are returned in a Cookies instance, which is a dict-like data structure with additional API for accessing cookies by their domain or path. >>> cookies = httpx . Cookies () >>> cookies . set ( 'cookie_on_domain' , 'hello, there!' , domain = 'httpbin.org' ) >>> cookies . set ( 'cookie_off_domain' , 'nope.' , domain = 'example.org' ) >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'cookie_on_domain' : 'hello, there!' }} Redirection and History By default, HTTPX will follow redirects for anything except HEAD requests. The history property of the response can be used to inspect any followed redirects. It contains a list of any redirect responses that were followed, in the order in which they were made. For example, GitHub redirects all HTTP requests to HTTPS. >>> r = httpx . get ( 'http://github.com/' ) >>> r . url URL ( 'https://github.com/' ) >>> r . status_code 200 >>> r . history [ < Response [ 301 Moved Permanently ] > ] You can modify the default redirection handling with the allow_redirects parameter: >>> r = httpx . get ( 'http://github.com/' , allow_redirects = False ) >>> r . status_code 301 >>> r . history [] If you\u2019re making a HEAD request, you can use this to enable redirection: >>> r = httpx . head ( 'http://github.com/' , allow_redirects = True ) >>> r . url 'https://github.com/' >>> r . history [ < Response [ 301 Moved Permanently ] > ] Timeouts HTTPX defaults to including reasonable timeouts for all network operations, meaning that if a connection is not properly established then it should always raise an error rather than hanging indefinitely. The default timeout for network inactivity is five seconds. You can modify the value to be more or less strict: >>> httpx . get ( 'https://github.com/' , timeout = 0.001 ) You can also disable the timeout behavior completely... >>> httpx . get ( 'https://github.com/' , timeout = None ) For advanced timeout management, see Timeout fine-tuning . Authentication HTTPX supports Basic and Digest HTTP authentication. To provide Basic authentication credentials, pass a 2-tuple of plaintext str or bytes objects as the auth argument to the request functions: >>> httpx . get ( \"https://example.com\" , auth = ( \"my_user\" , \"password123\" )) To provide credentials for Digest authentication you'll need to instantiate a DigestAuth object with the plaintext username and password as arguments. This object can be then passed as the auth argument to the request methods as above: >>> auth = httpx . DigestAuth ( \"my_user\" , \"password123\" ) >>> httpx . get ( \"https://example.com\" , auth = auth ) < Response [ 200 OK ] >","title":"QuickStart"},{"location":"quickstart/#quickstart","text":"First, start by importing HTTPX: >>> import httpx Now, let\u2019s try to get a webpage. >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r < Response [ 200 OK ] > Similarly, to make an HTTP POST request: >>> r = httpx . post ( 'https://httpbin.org/post' , data = { 'key' : 'value' }) The PUT, DELETE, HEAD, and OPTIONS requests all follow the same style: >>> r = httpx . put ( 'https://httpbin.org/put' , data = { 'key' : 'value' }) >>> r = httpx . delete ( 'https://httpbin.org/delete' ) >>> r = httpx . head ( 'https://httpbin.org/get' ) >>> r = httpx . options ( 'https://httpbin.org/get' )","title":"QuickStart"},{"location":"quickstart/#passing-parameters-in-urls","text":"To include URL query parameters in the request, use the params keyword: >>> params = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) To see how the values get encoding into the URL string, we can inspect the resulting URL that was used to make the request: >>> r . url URL ( 'https://httpbin.org/get?key2=value2&key1=value1' ) You can also pass a list of items as a value: >>> params = { 'key1' : 'value1' , 'key2' : [ 'value2' , 'value3' ]} >>> r = httpx . get ( 'https://httpbin.org/get' , params = params ) >>> r . url URL ( 'https://httpbin.org/get?key1=value1&key2=value2&key2=value3' )","title":"Passing Parameters in URLs"},{"location":"quickstart/#response-content","text":"HTTPX will automatically handle decoding the response content into Unicode text. >>> r = httpx . get ( 'https://www.example.org/' ) >>> r . text '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' You can inspect what encoding has been used to decode the response. >>> r . encoding 'UTF-8' If you need to override the standard behavior and explicitly set the encoding to use, then you can do that too. >>> r . encoding = 'ISO-8859-1'","title":"Response Content"},{"location":"quickstart/#binary-response-content","text":"The response content can also be accessed as bytes, for non-text responses: >>> r . content b '<!doctype html> \\n <html> \\n <head> \\n <title>Example Domain</title>...' Any gzip and deflate HTTP response encodings will automatically be decoded for you. If brotlipy is installed, then the brotli response encoding will also be supported. For example, to create an image from binary data returned by a request, you can use the following code: >>> from PIL import Image >>> from io import BytesIO >>> i = Image . open ( BytesIO ( r . content ))","title":"Binary Response Content"},{"location":"quickstart/#json-response-content","text":"Often Web API responses will be encoded as JSON. >>> r = httpx . get ( 'https://api.github.com/events' ) >>> r . json () [{ u 'repository' : { u 'open_issues' : 0 , u 'url' : 'https://github.com/...' ... }}]","title":"JSON Response Content"},{"location":"quickstart/#custom-headers","text":"To include additional headers in the outgoing request, use the headers keyword argument: >>> url = 'http://httpbin.org/headers' >>> headers = { 'user-agent' : 'my-app/0.0.1' } >>> r = httpx . get ( url , headers = headers )","title":"Custom Headers"},{"location":"quickstart/#sending-form-encoded-data","text":"Some types of HTTP requests, such as POST and PUT requests, can include data in the request body. One common way of including that is as form-encoded data, which is used for HTML forms. >>> data = { 'key1' : 'value1' , 'key2' : 'value2' } >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key2\" : \"value2\" , \"key1\" : \"value1\" }, ... } Form encoded data can also include multiple values form a given key. >>> data = { 'key1' : [ 'value1' , 'value2' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , data = data ) >>> print ( r . text ) { ... \"form\" : { \"key1\" : [ \"value1\" , \"value2\" ] }, ... }","title":"Sending Form Encoded Data"},{"location":"quickstart/#sending-multipart-file-uploads","text":"You can also upload files, using HTTP multipart encoding: >>> files = { 'upload-file' : open ( 'report.xls' , 'rb' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... } You can also explicitly set the filename and content type, by using a tuple of items for the file value: >>> files = { 'upload-file' : ( 'report.xls' , open ( 'report.xls' , 'rb' ), 'application/vnd.ms-excel' )} >>> r = httpx . post ( \"https://httpbin.org/post\" , files = files ) >>> print ( r . text ) { ... \"files\" : { \"upload-file\" : \"<... binary content ...>\" }, ... }","title":"Sending Multipart File Uploads"},{"location":"quickstart/#sending-json-encoded-data","text":"Form encoded data is okay if all you need is a simple key-value data structure. For more complicated data structures you'll often want to use JSON encoding instead. >>> data = { 'integer' : 123 , 'boolean' : True , 'list' : [ 'a' , 'b' , 'c' ]} >>> r = httpx . post ( \"https://httpbin.org/post\" , json = data ) >>> print ( r . text ) { ... \"json\" : { \"boolean\" : true , \"integer\" : 123 , \"list\" : [ \"a\" , \"b\" , \"c\" ] }, ... }","title":"Sending JSON Encoded Data"},{"location":"quickstart/#sending-binary-request-data","text":"For other encodings, you should use either a bytes type or a generator that yields bytes . You'll probably also want to set a custom Content-Type header when uploading binary data.","title":"Sending Binary Request Data"},{"location":"quickstart/#response-status-codes","text":"We can inspect the HTTP status code of the response: >>> r = httpx . get ( 'https://httpbin.org/get' ) >>> r . status_code 200 HTTPX also includes an easy shortcut for accessing status codes by their text phrase. >>> r . status_code == httpx . codes . OK True We can raise an exception for any Client or Server error responses (4xx or 5xx status codes): >>> not_found = httpx . get ( 'https://httpbin.org/status/404' ) >>> not_found . status_code 404 >>> not_found . raise_for_status () Traceback ( most recent call last ): File \"/Users/tomchristie/GitHub/encode/httpcore/httpx/models.py\" , line 776 , in raise_for_status raise HttpError ( message ) httpx . exceptions . HttpError : 404 Not Found Any successful response codes will simply return None rather than raising an exception. >>> r . raise_for_status ()","title":"Response Status Codes"},{"location":"quickstart/#response-headers","text":"The response headers are available as a dictionary-like interface. >>> r . headers Headers ({ 'content-encoding' : 'gzip' , 'transfer-encoding' : 'chunked' , 'connection' : 'close' , 'server' : 'nginx/1.0.4' , 'x-runtime' : '148ms' , 'etag' : '\"e1ca502697e5c9317743dc078f67693f\"' , 'content-type' : 'application/json' }) The Headers data type is case-insensitive, so you can use any capitalization. >>> r . headers [ 'Content-Type' ] 'application/json' >>> r . headers . get ( 'content-type' ) 'application/json' Multiple values for a single response header are represented as a single comma-separated value, as per RFC 7230 : A recipient MAY combine multiple header fields with the same field name into one \u201cfield-name: field-value\u201d pair, without changing the semantics of the message, by appending each subsequent field-value to the combined field value in order, separated by a comma.","title":"Response Headers"},{"location":"quickstart/#streaming-responses","text":"For large downloads you may want to use streaming responses that do not load the entire response body into memory at once. You can stream the binary content of the response... >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for data in r . iter_bytes (): ... print ( data ) Or the text of the response... >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for text in r . iter_text (): ... print ( text ) Or stream the text, on a line-by-line basis... >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for line in r . iter_lines (): ... print ( line ) HTTPX will use universal line endings, normalising all cases to \\n . In some cases you might want to access the raw bytes on the response without applying any HTTP content decoding. In this case any content encoding that the web server has applied such as gzip , deflate , or brotli will not be automatically decoded. >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... for chunk in r . iter_raw (): ... print ( chunk ) If you're using streaming responses in any of these ways then the response.content and response.text attributes will not be available, and will raise errors if accessed. However you can also use the response streaming functionality to conditionally load the response body: >>> with httpx . stream ( \"GET\" , \"https://www.example.com\" ) as r : ... if r . headers [ 'Content-Length' ] < TOO_LONG : ... r . read () ... print ( r . text )","title":"Streaming Responses"},{"location":"quickstart/#cookies","text":"Any cookies that are set on the response can be easily accessed: >>> r = httpx . get ( 'http://httpbin.org/cookies/set?chocolate=chip' , allow_redirects = False ) >>> r . cookies [ 'chocolate' ] 'chip' To include cookies in an outgoing request, use the cookies parameter: >>> cookies = { \"peanut\" : \"butter\" } >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'peanut' : 'butter' }} Cookies are returned in a Cookies instance, which is a dict-like data structure with additional API for accessing cookies by their domain or path. >>> cookies = httpx . Cookies () >>> cookies . set ( 'cookie_on_domain' , 'hello, there!' , domain = 'httpbin.org' ) >>> cookies . set ( 'cookie_off_domain' , 'nope.' , domain = 'example.org' ) >>> r = httpx . get ( 'http://httpbin.org/cookies' , cookies = cookies ) >>> r . json () { 'cookies' : { 'cookie_on_domain' : 'hello, there!' }}","title":"Cookies"},{"location":"quickstart/#redirection-and-history","text":"By default, HTTPX will follow redirects for anything except HEAD requests. The history property of the response can be used to inspect any followed redirects. It contains a list of any redirect responses that were followed, in the order in which they were made. For example, GitHub redirects all HTTP requests to HTTPS. >>> r = httpx . get ( 'http://github.com/' ) >>> r . url URL ( 'https://github.com/' ) >>> r . status_code 200 >>> r . history [ < Response [ 301 Moved Permanently ] > ] You can modify the default redirection handling with the allow_redirects parameter: >>> r = httpx . get ( 'http://github.com/' , allow_redirects = False ) >>> r . status_code 301 >>> r . history [] If you\u2019re making a HEAD request, you can use this to enable redirection: >>> r = httpx . head ( 'http://github.com/' , allow_redirects = True ) >>> r . url 'https://github.com/' >>> r . history [ < Response [ 301 Moved Permanently ] > ]","title":"Redirection and History"},{"location":"quickstart/#timeouts","text":"HTTPX defaults to including reasonable timeouts for all network operations, meaning that if a connection is not properly established then it should always raise an error rather than hanging indefinitely. The default timeout for network inactivity is five seconds. You can modify the value to be more or less strict: >>> httpx . get ( 'https://github.com/' , timeout = 0.001 ) You can also disable the timeout behavior completely... >>> httpx . get ( 'https://github.com/' , timeout = None ) For advanced timeout management, see Timeout fine-tuning .","title":"Timeouts"},{"location":"quickstart/#authentication","text":"HTTPX supports Basic and Digest HTTP authentication. To provide Basic authentication credentials, pass a 2-tuple of plaintext str or bytes objects as the auth argument to the request functions: >>> httpx . get ( \"https://example.com\" , auth = ( \"my_user\" , \"password123\" )) To provide credentials for Digest authentication you'll need to instantiate a DigestAuth object with the plaintext username and password as arguments. This object can be then passed as the auth argument to the request methods as above: >>> auth = httpx . DigestAuth ( \"my_user\" , \"password123\" ) >>> httpx . get ( \"https://example.com\" , auth = auth ) < Response [ 200 OK ] >","title":"Authentication"}]}